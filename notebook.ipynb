{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramtiin/Automated-Design-of-Symmetric-Autoencoders-Using-Genetic-Algorithms/blob/main/Automated_Design_of_Symmetric_Autoencoders_Using_Genetic_Algorithms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Below is a summary of the study. For a more detailed analysis, please refer to the attached PDF file.**"
      ],
      "metadata": {
        "id": "v5G93We4f7ku"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Abstract"
      ],
      "metadata": {
        "id": "CLHWlUtneUj_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Notebook presents a novel approach for optimizing the architecture of symmetric, undercomplete autoencoders for dimensionality reduction using a genetic algorithm. The approach aims to find the optimal combination of the number of hidden layers, neurons per layer, activations, and optimizers for the autoencoder, with the goal of achieving good reconstruction quality as measured by the reconstruction loss. The proposed method is evaluated on a 16x16 MNIST dataset, and results show that the genetic algorithm-based approach is effective in finding suitable architectures for the autoencoder."
      ],
      "metadata": {
        "id": "IyOokV-lc_uT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Sample-Autoencoder-Architecture.png](data:image/png;base64,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)\n",
        "\n",
        "Figure 1: The general structure of an autoencoder. The encoder compresses the input data into a lower-dimensional latent space, and a symmetric decoder reconstructs the input data from the latent space. The network is undercomplete, meaning that the dimensionality of the latent space is smaller than the input data, resulting in data compression and reconstruction loss."
      ],
      "metadata": {
        "id": "sLE7DofOddwz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction"
      ],
      "metadata": {
        "id": "9gxPkvj1eRsL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Autoencoders are a type of neural network that is commonly used for dimensionality reduction, feature extraction, anomaly detection, and data reconstruction. They consist of an encoder that maps the input to a lower-dimensional code, and a decoder that reconstructs the input from the code (Fig 1). In this research, I propose a genetic algorithm-based approach for optimizing the architecture of symmetric, undercomplete autoencoders for dimensionality reduction, with desired code size. Genetic algorithms are search algorithms inspired by natural selection processes and are commonly used for optimization problems. They work by iteratively generating and selecting a population of potential solutions, known as individuals or chromosomes. In the context of neural network design, genetic algorithms can be used to automatically search for the optimal architecture and hyperparameters of a model."
      ],
      "metadata": {
        "id": "xOABmzgkdy2g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In my proposed approach, I have used a microbial genetic algorithm to search for the optimal architecture of symmetric autoencoders. The genotype, or genetic representation, of each individual in the population consists of the number of hidden layers, the number of neurons per layer, and the choice of activation and optimization functions. The fitness of each individual is determined by the reconstruction loss, which measures how well the input data is reconstructed 1 from the code. The genetic algorithm mutates, crosses over, and applies other biologically-inspired operators to find an optimal combination of these parameters for the autoencoder. The resulting autoencoder is expected to achieve good reconstruction quality, as measured by the reconstruction loss. \n",
        "The training and evaluation of the autoencoder are done on a 16x16 MNIST dataset, for increasing the training speed. In the end, I was able to find an optimal architecture, which can compress the MNIST data set to an array with a length of 4 and reconstruct the original data with a reasonable loss. \n",
        "\n",
        "Additionally, the proposed approach also allows for the specification of the desired code size, enabling the user to control the level of dimensionality reduction. This is particularly useful in applications where the amount of data reduction required is known in advance. Furthermore, the use of a symmetric architecture in the autoencoder ensures that the encoder and decoder have the same structure, making the model more robust and easier to train. \n",
        "\n",
        "In conclusion, the proposed approach of using a microbial genetic algorithm to optimize the architecture of symmetric, undercomplete autoencoders for dimensionality reduction, with desired code size, has been shown to be effective in finding optimal architectures that can achieve good reconstruction quality while reducing the dimensionality of the input data. This approach can be applied to other datasets and applications where dimensionality reduction is needed, making it a valuable tool for data preprocessing and analysis."
      ],
      "metadata": {
        "id": "Hbx2BTZoeEDe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Methodology"
      ],
      "metadata": {
        "id": "kjGN44iaeypq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The methodology of this study involved the use of a microbial genetic algorithm to optimize the architecture of symmetric-undercomplete autoencoders for dimensionality reduction. The GA approach was chosen for its ability to effectively explore the large, complex design space of neural network architectures. First. I divide the data set into a training set and a validation set. The training set consisted of 10000 data points, while the validation set consisted of 5000 data points.\n",
        "\n",
        "This division was done to speed up the training process. The fitness of each individual was determined by the reconstruction loss, which measures how well the input data is reconstructed from the code. The lower the reconstruction loss, the better the fitness of the individual.\n",
        "\n",
        "The genetic algorithm then used biologically-inspired operators such as mutation, crossover, and selection to generate new individuals and improve the population over multiple generations. This process was repeated until a satisfactory solution was found or a predetermined number of generations had passed."
      ],
      "metadata": {
        "id": "CtGDF_tTec57"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code"
      ],
      "metadata": {
        "id": "hRpt4K3VfsSY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAzce2dP_RNy"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Flatten,Dense,Input,Reshape\n",
        "from tensorflow.keras.models import Sequential\n",
        "from random import randrange"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjUnymi8_DxO",
        "outputId": "b7985110-3b6c-4782-ffac-d0c289c8a660"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 16, 16, 1)\n"
          ]
        }
      ],
      "source": [
        "(X_train, y_train) , (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "\n",
        "# expand new axis, channel axis \n",
        "X_train = np.expand_dims(X_train, axis=-1)\n",
        "\n",
        "# it's always better to normalize \n",
        "X_train = X_train.astype('float32') / 255\n",
        "\n",
        "# resize the input shape , i.e. old shape: 28, new shape: 16\n",
        "X_train = tf.image.resize(X_train, [16,16]) # if we want to resize \n",
        "\n",
        "print(X_train.shape)\n",
        "# (60000, 32, 32, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5j_UiY4_NEcl"
      },
      "outputs": [],
      "source": [
        "X_train = X_train[:, :, :,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLiRuJ8O_P7B"
      },
      "outputs": [],
      "source": [
        "X_test = X_train[10000:15000]\n",
        "X_train = X_train[0:10000]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSvunAoc7E5o",
        "outputId": "6ae5e26d-b6ad-4309-fc05-e1dc0b1f1942"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([5000, 16, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "MmNY_3Fn_Xps",
        "outputId": "5f21c3b2-631d-46f3-9a93-9190b95281a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff853768130>"
            ]
          },
          "metadata": {},
          "execution_count": 99
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(X_train[0], cmap=plt.cm.gray_r, interpolation=\"nearest\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aa7zkIIEDxdE"
      },
      "outputs": [],
      "source": [
        "# DNA[0] = activations\n",
        "# DNA[1] = optimizer\n",
        "DNA_parameter = [[\"tanh\",\"softmax\",\"relu\",\"sigmoid\",\"linear\"],\n",
        "                 [\"sgd\",\"adam\"]]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class architecture:\n",
        "    def __init__(self, neurons=None, activation=None, optimizer=None):\n",
        "        self.neurons = neurons\n",
        "        self.activation = activation\n",
        "        self.optimizer = optimizer"
      ],
      "metadata": {
        "id": "Ej9R8bigaLyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "This code defines a class called \"Autoencoder\" which inherits from the \"Model\" class from Tensorflow's Keras library.\n",
        "The class has two main components: an encoder and a decoder, which are passed as arguments to the class constructor.\n",
        "The class overrides the call() method, which takes an input x, and applies the encoder on it to get an encoded version of the input, and then applies the decoder on the encoded input to get the final decoded output.\n",
        "'''\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "class Autoencoder(Model):\n",
        "  def __init__(self, encoder, decoder):\n",
        "    super(Autoencoder, self).__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded"
      ],
      "metadata": {
        "id": "-cxmyQkrpj62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkxLlq2cQxrF"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "This code defines several functions related to creating and training autoencoders.\n",
        "The first function, create_population(), creates a list of \"architectures\" which represent the different configurations of the autoencoder. It takes in 3 arguments: hidden_layers, DNA_parameter, population_size. It creates a list of architectures with random choices of activation functions, number of neurons per layer, optimizers.\n",
        "The second function, mirror_model_architecture(), takes in an existing autoencoder model, and creates a mirrored version of that model (the decoder) by reversing the order of its layers.\n",
        "The last function, create_model(), takes in an architecture, creates an encoder and a decoder for that architecture, creates an autoencoder by combining the encoder and decoder, and returns the autoencoder. The function creates the encoder by adding layers of dense units with random number of neurons, activation functions and optimizer. The decoder is created by reversing the layers of the encoder. The autoencoder is then compiled with a mean squared error loss function and optimizer.\n",
        "'''\n",
        "\n",
        "def create_population(hidden_layers,DNA_parameter,population_size=20):\n",
        "  architectures=[]\n",
        "\n",
        "  # unfold DNA_parameters:\n",
        "  activations = DNA_parameter[0]\n",
        "  optimizers = DNA_parameter[1]\n",
        "  \n",
        "\n",
        "  for pop in range(population_size):\n",
        "\n",
        "    the_architecture=[]\n",
        "\n",
        "    #We only need to create and optimize architecture for half of the depth of the network because we want to create symmetric autoencoders\n",
        "    for i in range(hidden_layers):\n",
        "        activation  = np.random.choice(activations)\n",
        "        neurons_per_layer =  np.random.rand()\n",
        "        the_architecture.append(architecture(neurons=neurons_per_layer,activation=activation))\n",
        "    the_architecture.append(architecture(activation=np.random.choice(activations)))\n",
        "    the_architecture.append(architecture(activation=np.random.choice(activations)))\n",
        "    the_architecture.append(architecture(optimizer=np.random.choice(optimizers)))\n",
        "    architectures.append(the_architecture)\n",
        "  return architectures\n",
        "\n",
        "def mirror_model_architecture(model):\n",
        "  mirrored_model = tf.keras.models.Sequential()\n",
        "  for layer in reversed(model.layers):\n",
        "    mirrored_model.add(layer)\n",
        "  return mirrored_model\n",
        "\n",
        "def create_model(architecture,code_size):\n",
        "\n",
        "        \n",
        "    encoder = Sequential()\n",
        "    encoder.add(tf.keras.Input(shape=(16,16)))\n",
        "    encoder.add(Flatten())\n",
        "\n",
        "    hidden_layers = (len(architecture)-3)\n",
        "    \n",
        "    actual_neurons = []\n",
        "    actual_neurons.append(16*16)\n",
        "\n",
        "    for i in range(1,hidden_layers):\n",
        "      if i < hidden_layers:\n",
        "        dense_units = round((architecture[i].neurons)*actual_neurons[i-1])\n",
        "\n",
        "        if dense_units==0 or dense_units<code_size:\n",
        "          actual_neurons.append(0)\n",
        "          pass\n",
        "        else:\n",
        "          actual_neurons.append(dense_units)\n",
        "          encoder.add(Dense(units=dense_units, activation = architecture[i].activation))\n",
        "  \n",
        "    encoder.add(Dense(units=code_size, activation = architecture[i].activation))\n",
        "    decoder = Sequential()\n",
        "    decoder_layers_list = []\n",
        "    for i in range(len(encoder.layers)-2,0,-1):\n",
        "      decoder_layers_list.append([encoder.layers[i].units,encoder.layers[i].activation])\n",
        "\n",
        "    for layer in decoder_layers_list:\n",
        "      decoder.add(Dense(units=layer[0], activation = layer[1]))\n",
        " \n",
        "    decoder.add(Dense(units=16*16, activation = architecture[-2].activation))\n",
        "    decoder.add(Reshape((16, 16)))\n",
        "    autoencoder = Autoencoder(encoder, decoder)\n",
        "    autoencoder.compile(optimizer=architecture[-1].optimizer, loss=\"mse\")\n",
        "    #autoencoder.build()\n",
        "    return autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVv51IbcU2C2"
      },
      "outputs": [],
      "source": [
        "#This line of code creates a list of \"architectures\" by calling the create_population() function. It specifies that the autoencoder should have 3 hidden layers, uses the DNA_parameter which is passed as an argument, and creates a population of 20 architectures. The returned list of architectures can be used to create autoencoder models using the create_model() function.\n",
        "population = create_population(3,DNA_parameter,population_size=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCcDEf_s_wn8"
      },
      "outputs": [],
      "source": [
        "def train(model,epochs=2):\n",
        "  return model.fit(X_train, X_train, \n",
        "          epochs=epochs, \n",
        "          batch_size=32,\n",
        "          validation_data=(X_test, X_test),\n",
        "          shuffle=True)\n",
        "def fitness(loss):\n",
        "  return loss[0] * -1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#It's a way of displaying the architecture, so that it's easy to read and understand.\n",
        "def print_architecture(architecture):\n",
        "  lst=[]\n",
        "  for arch in architecture:\n",
        "    tmp=[]\n",
        "    if arch.neurons!=None:\n",
        "      tmp.append(arch.neurons)\n",
        "    if arch.activation!=None:\n",
        "      tmp.append(arch.activation)\n",
        "    if arch.optimizer!=None:\n",
        "      tmp.append(arch.optimizer)\n",
        "    lst.append(tmp)\n",
        "  print(lst)"
      ],
      "metadata": {
        "id": "OUtS75ZWmfqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This one shows the real numbers of neurons instead of percentage\n",
        "def print_architecture_with_real_values(architecture):\n",
        "  lst=[]\n",
        "  neurons = [256]\n",
        "  for arch in architecture:\n",
        "    tmp=[]\n",
        "    if arch.neurons!=None:\n",
        "      tmp.append(round(neurons[-1]*arch.neurons))\n",
        "      neurons.append(round(neurons[-1]*arch.neurons))\n",
        "    if arch.activation!=None:\n",
        "      tmp.append(arch.activation)\n",
        "    if arch.optimizer!=None:\n",
        "      tmp.append(arch.optimizer)\n",
        "    lst.append(tmp)\n",
        "  print(lst)"
      ],
      "metadata": {
        "id": "NtGbraweNgY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkGSOaCbZyPk"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "This function is implementing a Genetic Algorithm (GA) that uses the \"population\" of architectures to evolve the best architecture for an autoencoder. It takes several arguments like number of generations to run, code size, recombination rate, deme size, whether to use crossover and mutation or not.\n",
        "\n",
        "For each generation, it selects two random architectures, creates models for them, trains them and calculate their fitness. The architecture with the higher fitness is chosen as the winner and the other one is the loser. Then it performs crossover and mutation on the loser based on the recombination rate and mutation rate. The new offspring is then added back to the population and the process is repeated.\n",
        "\n",
        "The function also keeps track of the best fitness and best architecture found so far, and returns the best architecture and the best fitness over time. The function also uses the clear_session() method from Tensorflow to clear the session after each generation to prevent tensorflow from consuming too much memory.\n",
        "'''\n",
        "\n",
        "\n",
        "def GA(population,n_generations = 100,code_size=4,recombination_rate = 0.5,deme_size=5,Crossover=True,Mutation=True):\n",
        "\n",
        "  mutation_rate = 1/len(population[0])\n",
        "  best_fitness = -np.inf\n",
        "  best_architecture = []\n",
        "  pop_size = len(population)\n",
        "  offspring_fitness_over_time = []\n",
        "\n",
        "  activations = DNA_parameter[0]\n",
        "  optimizers = DNA_parameter[1]\n",
        "\n",
        "  for i in range(n_generations):\n",
        "      print(\"Generation:\",i)\n",
        "\n",
        "      rand_genotype_1 = np.random.randint(0, pop_size)\n",
        "      rand_genotype_2 = (rand_genotype_1+1+np.random.randint(0, deme_size))%pop_size\n",
        "\n",
        "\n",
        "\n",
        "      P1= population[rand_genotype_1]\n",
        "      P2= population[rand_genotype_2]\n",
        "\n",
        "      \n",
        "      P1_model = create_model(P1,code_size=code_size)\n",
        "      P2_model = create_model(P2,code_size=code_size)\n",
        "      \n",
        "\n",
        "      his_1 = train(P1_model)\n",
        "      his_2 = train(P2_model)\n",
        "\n",
        "      fitness_P1 = fitness(his_1.history[\"loss\"])\n",
        "      fitness_P2 = fitness(his_2.history[\"loss\"])\n",
        "\n",
        "      if (fitness_P1>fitness_P2):\n",
        "        Winner = P1\n",
        "        Loser = P2\n",
        "        Loser_idx = rand_genotype_2\n",
        "      else:\n",
        "        Winner = P2\n",
        "        Loser = P1\n",
        "        Loser_idx = rand_genotype_1\n",
        "\n",
        "\n",
        "      print(\"Winner: \")\n",
        "      print_architecture(Winner)\n",
        "      print(\"Loser: \")\n",
        "      print_architecture(Loser)\n",
        "        \n",
        "\n",
        "      for k in range(len(Loser)):\n",
        "        if Crossover:\n",
        "          if np.random.rand() < recombination_rate:\n",
        "              Loser[k] = Winner[k]\n",
        "        if Mutation:\n",
        "          if np.random.rand() <1:\n",
        "            if k<(len(Loser)-3):\n",
        "              activation  = np.random.choice(activations)\n",
        "              neurons = np.random.rand()\n",
        "              Loser[k] = architecture(neurons=neurons,activation=activation)\n",
        "            elif k>=(len(Loser)-3) and k!=len(Loser)-1:\n",
        "              activation  = np.random.choice(activations)\n",
        "              Loser[k] = architecture(activation=activation)\n",
        "            else:\n",
        "              optimizer =  np.random.choice(optimizers)\n",
        "              Loser[k] = architecture(optimizer=optimizer)\n",
        "\n",
        "\n",
        "      print(\"Child: \")\n",
        "      print_architecture(Loser)\n",
        "      \n",
        "\n",
        "\n",
        "      population[Loser_idx] = Loser #Replacing the genotype in population\n",
        "\n",
        "      offspring_model= create_model(Loser,code_size=code_size)\n",
        "      his_offspring = train(offspring_model)\n",
        "      offspring_fitness = fitness(his_offspring.history[\"loss\"])\n",
        "\n",
        "\n",
        "      if best_fitness < offspring_fitness:\n",
        "        best_fitness = offspring_fitness\n",
        "        best_architecture.append(Loser)\n",
        "        print_architecture_with_real_values(best_architecture[-1])\n",
        "        print(best_fitness)\n",
        "      offspring_fitness_over_time.append(best_fitness)\n",
        "      tf.keras.backend.clear_session()\n",
        "\n",
        "      \n",
        "      print(\"__________________\")\n",
        "\n",
        "\n",
        "\n",
        "  return offspring_fitness_over_time,best_architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f46CpDncLMwn",
        "outputId": "5f587488-5767-4da9-bb6c-379b80db2baa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation: 0\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.2199 - val_loss: 0.2193\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.2186 - val_loss: 0.2181\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 7ms/step - loss: 0.1124 - val_loss: 0.0882\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0815 - val_loss: 0.0830\n",
            "Winner: \n",
            "[[0.9775586135482421, 'sigmoid'], [0.8890705468421936, 'sigmoid'], [0.7349183850067187, 'relu'], ['tanh'], ['relu'], ['sgd']]\n",
            "Loser: \n",
            "[[0.8301923458152872, 'relu'], [0.5029158962227244, 'relu'], [0.8179553648826428, 'linear'], ['relu'], ['sigmoid'], ['sgd']]\n",
            "Child: \n",
            "[[0.10922897397984355, 'softmax'], [0.46413907021136735, 'linear'], [0.29905091241460025, 'sigmoid'], ['tanh'], ['sigmoid'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.2162 - val_loss: 0.2111\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.2058 - val_loss: 0.2011\n",
            "[[28, 'softmax'], [13, 'linear'], [4, 'sigmoid'], ['tanh'], ['sigmoid'], ['sgd']]\n",
            "-0.21616357564926147\n",
            "__________________\n",
            "Generation: 1\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.2195 - val_loss: 0.2193\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.2190 - val_loss: 0.2188\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0672 - val_loss: 0.0508\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0473 - val_loss: 0.0476\n",
            "Winner: \n",
            "[[0.11546602562561492, 'tanh'], [0.1259669620859294, 'linear'], [0.04246090167690786, 'relu'], ['linear'], ['sigmoid'], ['adam']]\n",
            "Loser: \n",
            "[[0.0940323688639576, 'linear'], [0.7498344748007535, 'softmax'], [0.6482568345674975, 'tanh'], ['relu'], ['sigmoid'], ['sgd']]\n",
            "Child: \n",
            "[[0.7868626821199968, 'softmax'], [0.12227392203220333, 'softmax'], [0.48899820875078903, 'tanh'], ['tanh'], ['linear'], ['adam']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0653 - val_loss: 0.0556\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0515 - val_loss: 0.0514\n",
            "[[201, 'softmax'], [25, 'softmax'], [12, 'tanh'], ['tanh'], ['linear'], ['adam']]\n",
            "-0.06528366357088089\n",
            "__________________\n",
            "Generation: 2\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0423 - val_loss: 0.0360\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0312 - val_loss: 0.0304\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0678 - val_loss: 0.0535\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0484 - val_loss: 0.0474\n",
            "Winner: \n",
            "[[0.14734891885940837, 'linear'], [0.8668511904168803, 'relu'], [0.625084948095747, 'relu'], ['relu'], ['linear'], ['adam']]\n",
            "Loser: \n",
            "[[0.11546602562561492, 'tanh'], [0.1259669620859294, 'linear'], [0.04246090167690786, 'relu'], ['linear'], ['sigmoid'], ['adam']]\n",
            "Child: \n",
            "[[0.15924994314244878, 'softmax'], [0.09292455711968906, 'softmax'], [0.9928997308718939, 'softmax'], ['tanh'], ['linear'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1008 - val_loss: 0.1039\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0986 - val_loss: 0.1017\n",
            "__________________\n",
            "Generation: 3\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 3ms/step - loss: 0.2186 - val_loss: 0.2181\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2175 - val_loss: 0.2170\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0654 - val_loss: 0.0580\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0533 - val_loss: 0.0531\n",
            "Winner: \n",
            "[[0.7868626821199968, 'softmax'], [0.12227392203220333, 'softmax'], [0.48899820875078903, 'tanh'], ['tanh'], ['linear'], ['adam']]\n",
            "Loser: \n",
            "[[0.7843890977779845, 'sigmoid'], [0.023177467733218382, 'sigmoid'], [0.8835907728306842, 'tanh'], ['softmax'], ['sigmoid'], ['sgd']]\n",
            "Child: \n",
            "[[0.416494741847798, 'softmax'], [0.016140423345351373, 'relu'], [0.12672924263977559, 'linear'], ['sigmoid'], ['softmax'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "__________________\n",
            "Generation: 4\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 3ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 7ms/step - loss: 0.0959 - val_loss: 0.0995\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0952 - val_loss: 0.0994\n",
            "Winner: \n",
            "[[0.5066952180295587, 'sigmoid'], [0.8532374791648694, 'linear'], [0.4097462670709051, 'linear'], ['tanh'], ['softmax'], ['adam']]\n",
            "Loser: \n",
            "[[0.7635012587611537, 'relu'], [0.11224434768583225, 'relu'], [0.9412856663780849, 'relu'], ['tanh'], ['softmax'], ['sgd']]\n",
            "Child: \n",
            "[[0.8851226868870943, 'linear'], [0.6811088579387302, 'sigmoid'], [0.21034277249834088, 'linear'], ['sigmoid'], ['softmax'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "__________________\n",
            "Generation: 5\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0481 - val_loss: 0.0403\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0391 - val_loss: 0.0397\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1062 - val_loss: 0.0873\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0808 - val_loss: 0.0827\n",
            "Winner: \n",
            "[[0.5759832487742217, 'linear'], [0.15760432802924507, 'linear'], [0.3227868462787148, 'linear'], ['softmax'], ['tanh'], ['adam']]\n",
            "Loser: \n",
            "[[0.9775586135482421, 'sigmoid'], [0.8890705468421936, 'sigmoid'], [0.7349183850067187, 'relu'], ['tanh'], ['relu'], ['sgd']]\n",
            "Child: \n",
            "[[0.8633232522497706, 'sigmoid'], [0.08632177387565998, 'softmax'], [0.5324302641552852, 'tanh'], ['sigmoid'], ['linear'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1001 - val_loss: 0.1032\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0979 - val_loss: 0.1010\n",
            "__________________\n",
            "Generation: 6\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1128 - val_loss: 0.0892\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0816 - val_loss: 0.0829\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0428 - val_loss: 0.0383\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0353 - val_loss: 0.0358\n",
            "Winner: \n",
            "[[0.14734891885940837, 'linear'], [0.8668511904168803, 'relu'], [0.625084948095747, 'relu'], ['relu'], ['linear'], ['adam']]\n",
            "Loser: \n",
            "[[0.6550422506167627, 'softmax'], [0.8213703906794555, 'sigmoid'], [0.39894150911378423, 'softmax'], ['softmax'], ['relu'], ['sgd']]\n",
            "Child: \n",
            "[[0.4926819460442493, 'tanh'], [0.7873227444031787, 'linear'], [0.2857031394517229, 'linear'], ['relu'], ['linear'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1063 - val_loss: 0.1051\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0975 - val_loss: 0.0984\n",
            "__________________\n",
            "Generation: 7\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0567 - val_loss: 0.0505\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0446 - val_loss: 0.0424\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.1069 - val_loss: 0.1074\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.1005 - val_loss: 0.1019\n",
            "Winner: \n",
            "[[0.057245223880398766, 'relu'], [0.20338296344634088, 'tanh'], [0.7221576026348004, 'sigmoid'], ['relu'], ['tanh'], ['adam']]\n",
            "Loser: \n",
            "[[0.2016353292818781, 'relu'], [0.5240545342595639, 'tanh'], [0.21013529150049404, 'linear'], ['linear'], ['tanh'], ['sgd']]\n",
            "Child: \n",
            "[[0.24413699957055524, 'relu'], [0.5197692674130492, 'linear'], [0.6488057524583702, 'softmax'], ['relu'], ['softmax'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "__________________\n",
            "Generation: 8\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0965 - val_loss: 0.0997\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0953 - val_loss: 0.0993\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0927 - val_loss: 0.0934\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0876 - val_loss: 0.0890\n",
            "Winner: \n",
            "[[0.5189234054653523, 'relu'], [0.0885073522935863, 'sigmoid'], [0.06400489496727468, 'linear'], ['relu'], ['relu'], ['sgd']]\n",
            "Loser: \n",
            "[[0.9539950659589137, 'tanh'], [0.2520860467379832, 'relu'], [0.3548709007555425, 'linear'], ['sigmoid'], ['softmax'], ['adam']]\n",
            "Child: \n",
            "[[0.8897384317892375, 'sigmoid'], [0.5095987066116655, 'relu'], [0.3916185428952589, 'linear'], ['softmax'], ['softmax'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "__________________\n",
            "Generation: 9\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0973 - val_loss: 0.1009\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0963 - val_loss: 0.1002\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Winner: \n",
            "[[0.42945519286572775, 'softmax'], [0.3839340417156384, 'sigmoid'], [0.5920513940878305, 'linear'], ['relu'], ['softmax'], ['adam']]\n",
            "Loser: \n",
            "[[0.8851226868870943, 'linear'], [0.6811088579387302, 'sigmoid'], [0.21034277249834088, 'linear'], ['sigmoid'], ['softmax'], ['sgd']]\n",
            "Child: \n",
            "[[0.2971364619150637, 'sigmoid'], [0.21088806319653175, 'sigmoid'], [0.12099487769494677, 'tanh'], ['linear'], ['sigmoid'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2206 - val_loss: 0.2173\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2137 - val_loss: 0.2106\n",
            "__________________\n",
            "Generation: 10\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.1059 - val_loss: 0.0910\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0822 - val_loss: 0.0818\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 5ms/step - loss: 0.0974 - val_loss: 0.1012\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0964 - val_loss: 0.1002\n",
            "Winner: \n",
            "[[0.42945519286572775, 'softmax'], [0.3839340417156384, 'sigmoid'], [0.5920513940878305, 'linear'], ['relu'], ['softmax'], ['adam']]\n",
            "Loser: \n",
            "[[0.25250791876801715, 'sigmoid'], [0.5107144344935234, 'sigmoid'], [0.008567570600177321, 'tanh'], ['softmax'], ['relu'], ['sgd']]\n",
            "Child: \n",
            "[[0.49801205309170515, 'sigmoid'], [0.5142888584805345, 'softmax'], [0.47751165602422974, 'linear'], ['linear'], ['softmax'], ['adam']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0995 - val_loss: 0.1035\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.0987 - val_loss: 0.1025\n",
            "__________________\n",
            "Generation: 11\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0577 - val_loss: 0.0519\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0465 - val_loss: 0.0448\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0950 - val_loss: 0.0964\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0910 - val_loss: 0.0929\n",
            "Winner: \n",
            "[[0.057245223880398766, 'relu'], [0.20338296344634088, 'tanh'], [0.7221576026348004, 'sigmoid'], ['relu'], ['tanh'], ['adam']]\n",
            "Loser: \n",
            "[[0.5189234054653523, 'relu'], [0.0885073522935863, 'sigmoid'], [0.06400489496727468, 'linear'], ['relu'], ['relu'], ['sgd']]\n",
            "Child: \n",
            "[[0.7256897870970546, 'sigmoid'], [0.6903209963888232, 'sigmoid'], [0.15978573240277405, 'softmax'], ['softmax'], ['tanh'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.1426 - val_loss: 0.0962\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0757 - val_loss: 0.0670\n",
            "__________________\n",
            "Generation: 12\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0995 - val_loss: 0.1035\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.0988 - val_loss: 0.1025\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0653 - val_loss: 0.0552\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0513 - val_loss: 0.0518\n",
            "Winner: \n",
            "[[0.7868626821199968, 'softmax'], [0.12227392203220333, 'softmax'], [0.48899820875078903, 'tanh'], ['tanh'], ['linear'], ['adam']]\n",
            "Loser: \n",
            "[[0.49801205309170515, 'sigmoid'], [0.5142888584805345, 'softmax'], [0.47751165602422974, 'linear'], ['linear'], ['softmax'], ['adam']]\n",
            "Child: \n",
            "[[0.46854394950240597, 'sigmoid'], [0.1938376376713814, 'softmax'], [0.21640028600754113, 'softmax'], ['tanh'], ['softmax'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "__________________\n",
            "Generation: 13\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.1674 - val_loss: 0.1062\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0782 - val_loss: 0.0658\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Winner: \n",
            "[[0.24413699957055524, 'relu'], [0.5197692674130492, 'linear'], [0.6488057524583702, 'softmax'], ['relu'], ['softmax'], ['sgd']]\n",
            "Loser: \n",
            "[[0.7256897870970546, 'sigmoid'], [0.6903209963888232, 'sigmoid'], [0.15978573240277405, 'softmax'], ['softmax'], ['tanh'], ['sgd']]\n",
            "Child: \n",
            "[[0.5318706287597973, 'relu'], [0.9510213299823685, 'tanh'], [0.21068121866140777, 'relu'], ['tanh'], ['sigmoid'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.2182 - val_loss: 0.2174\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.2164 - val_loss: 0.2155\n",
            "__________________\n",
            "Generation: 14\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0993 - val_loss: 0.1024\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0971 - val_loss: 0.1002\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.2195 - val_loss: 0.2193\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.2190 - val_loss: 0.2188\n",
            "Winner: \n",
            "[[0.8633232522497706, 'sigmoid'], [0.08632177387565998, 'softmax'], [0.5324302641552852, 'tanh'], ['sigmoid'], ['linear'], ['sgd']]\n",
            "Loser: \n",
            "[[0.34261266884137964, 'sigmoid'], [0.8123273683783793, 'softmax'], [0.029163985519858437, 'tanh'], ['relu'], ['sigmoid'], ['sgd']]\n",
            "Child: \n",
            "[[0.8140387296972396, 'relu'], [0.0031451029522431284, 'relu'], [0.23271340947689834, 'softmax'], ['tanh'], ['softmax'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "__________________\n",
            "Generation: 15\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0444 - val_loss: 0.0402\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0389 - val_loss: 0.0396\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0472 - val_loss: 0.0409\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0392 - val_loss: 0.0400\n",
            "Winner: \n",
            "[[0.569814623064877, 'tanh'], [0.8448147666569815, 'tanh'], [0.09883656670056751, 'tanh'], ['linear'], ['linear'], ['adam']]\n",
            "Loser: \n",
            "[[0.5759832487742217, 'linear'], [0.15760432802924507, 'linear'], [0.3227868462787148, 'linear'], ['softmax'], ['tanh'], ['adam']]\n",
            "Child: \n",
            "[[0.23450510117378154, 'relu'], [0.4172374005271141, 'relu'], [0.028488690967137797, 'sigmoid'], ['linear'], ['sigmoid'], ['adam']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0733 - val_loss: 0.0582\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0563 - val_loss: 0.0581\n",
            "__________________\n",
            "Generation: 16\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 3ms/step - loss: 0.0998 - val_loss: 0.1029\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0977 - val_loss: 0.1007\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0995 - val_loss: 0.1026\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0974 - val_loss: 0.1005\n",
            "Winner: \n",
            "[[0.8633232522497706, 'sigmoid'], [0.08632177387565998, 'softmax'], [0.5324302641552852, 'tanh'], ['sigmoid'], ['linear'], ['sgd']]\n",
            "Loser: \n",
            "[[0.15924994314244878, 'softmax'], [0.09292455711968906, 'softmax'], [0.9928997308718939, 'softmax'], ['tanh'], ['linear'], ['sgd']]\n",
            "Child: \n",
            "[[0.372314449263103, 'tanh'], [0.7153000479180676, 'linear'], [0.43873386860927377, 'relu'], ['sigmoid'], ['sigmoid'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.2190 - val_loss: 0.2185\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.2178 - val_loss: 0.2174\n",
            "__________________\n",
            "Generation: 17\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.2191 - val_loss: 0.2187\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.2179 - val_loss: 0.2174\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Winner: \n",
            "[[0.24413699957055524, 'relu'], [0.5197692674130492, 'linear'], [0.6488057524583702, 'softmax'], ['relu'], ['softmax'], ['sgd']]\n",
            "Loser: \n",
            "[[0.5318706287597973, 'relu'], [0.9510213299823685, 'tanh'], [0.21068121866140777, 'relu'], ['tanh'], ['sigmoid'], ['sgd']]\n",
            "Child: \n",
            "[[0.9770409194574108, 'tanh'], [0.4988330237550811, 'linear'], [0.47189709363717536, 'softmax'], ['softmax'], ['linear'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0987 - val_loss: 0.1011\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0952 - val_loss: 0.0976\n",
            "__________________\n",
            "Generation: 18\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0658 - val_loss: 0.0580\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0535 - val_loss: 0.0522\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0457 - val_loss: 0.0408\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.0365 - val_loss: 0.0357\n",
            "Winner: \n",
            "[[0.14734891885940837, 'linear'], [0.8668511904168803, 'relu'], [0.625084948095747, 'relu'], ['relu'], ['linear'], ['adam']]\n",
            "Loser: \n",
            "[[0.7868626821199968, 'softmax'], [0.12227392203220333, 'softmax'], [0.48899820875078903, 'tanh'], ['tanh'], ['linear'], ['adam']]\n",
            "Child: \n",
            "[[0.5762952169700479, 'sigmoid'], [0.15615652611684716, 'linear'], [0.9951994531165488, 'sigmoid'], ['softmax'], ['tanh'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 3ms/step - loss: 0.1222 - val_loss: 0.1090\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0970 - val_loss: 0.0946\n",
            "__________________\n",
            "Generation: 19\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0733 - val_loss: 0.0582\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0563 - val_loss: 0.0581\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0995 - val_loss: 0.1018\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0958 - val_loss: 0.0982\n",
            "Winner: \n",
            "[[0.23450510117378154, 'relu'], [0.4172374005271141, 'relu'], [0.028488690967137797, 'sigmoid'], ['linear'], ['sigmoid'], ['adam']]\n",
            "Loser: \n",
            "[[0.9770409194574108, 'tanh'], [0.4988330237550811, 'linear'], [0.47189709363717536, 'softmax'], ['softmax'], ['linear'], ['sgd']]\n",
            "Child: \n",
            "[[0.6902528490744793, 'tanh'], [0.35458497867970773, 'sigmoid'], [0.35274975460726166, 'softmax'], ['linear'], ['sigmoid'], ['adam']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0674 - val_loss: 0.0584\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0564 - val_loss: 0.0582\n",
            "__________________\n",
            "Generation: 20\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1037 - val_loss: 0.1023\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0948 - val_loss: 0.0950\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0456 - val_loss: 0.0400\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0370 - val_loss: 0.0366\n",
            "Winner: \n",
            "[[0.14734891885940837, 'linear'], [0.8668511904168803, 'relu'], [0.625084948095747, 'relu'], ['relu'], ['linear'], ['adam']]\n",
            "Loser: \n",
            "[[0.4926819460442493, 'tanh'], [0.7873227444031787, 'linear'], [0.2857031394517229, 'linear'], ['relu'], ['linear'], ['sgd']]\n",
            "Child: \n",
            "[[0.9111233110350488, 'sigmoid'], [0.45829621813402954, 'sigmoid'], [0.8352668185787894, 'sigmoid'], ['sigmoid'], ['linear'], ['adam']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0601 - val_loss: 0.0580\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.0535 - val_loss: 0.0523\n",
            "[[233, 'sigmoid'], [107, 'sigmoid'], [89, 'sigmoid'], ['sigmoid'], ['linear'], ['adam']]\n",
            "-0.060090165585279465\n",
            "__________________\n",
            "Generation: 21\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.2292 - val_loss: 0.2256\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2220 - val_loss: 0.2186\n",
            "Winner: \n",
            "[[0.416494741847798, 'softmax'], [0.016140423345351373, 'relu'], [0.12672924263977559, 'linear'], ['sigmoid'], ['softmax'], ['sgd']]\n",
            "Loser: \n",
            "[[0.2971364619150637, 'sigmoid'], [0.21088806319653175, 'sigmoid'], [0.12099487769494677, 'tanh'], ['linear'], ['sigmoid'], ['sgd']]\n",
            "Child: \n",
            "[[0.6198159910348582, 'linear'], [0.5590531582864904, 'sigmoid'], [0.5232156490604428, 'linear'], ['linear'], ['linear'], ['adam']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0509 - val_loss: 0.0410\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0380 - val_loss: 0.0370\n",
            "[[159, 'linear'], [89, 'sigmoid'], [47, 'linear'], ['linear'], ['linear'], ['adam']]\n",
            "-0.050906095653772354\n",
            "__________________\n",
            "Generation: 22\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0726 - val_loss: 0.0582\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0563 - val_loss: 0.0581\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0677 - val_loss: 0.0585\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0565 - val_loss: 0.0582\n",
            "Winner: \n",
            "[[0.6902528490744793, 'tanh'], [0.35458497867970773, 'sigmoid'], [0.35274975460726166, 'softmax'], ['linear'], ['sigmoid'], ['adam']]\n",
            "Loser: \n",
            "[[0.23450510117378154, 'relu'], [0.4172374005271141, 'relu'], [0.028488690967137797, 'sigmoid'], ['linear'], ['sigmoid'], ['adam']]\n",
            "Child: \n",
            "[[0.9694988990816781, 'linear'], [0.30419274846329925, 'relu'], [0.0771577187862783, 'tanh'], ['linear'], ['sigmoid'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.2192 - val_loss: 0.2189\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2184 - val_loss: 0.2181\n",
            "__________________\n",
            "Generation: 23\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 6ms/step - loss: 0.0437 - val_loss: 0.0401\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0389 - val_loss: 0.0395\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0552 - val_loss: 0.0486\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0447 - val_loss: 0.0445\n",
            "Winner: \n",
            "[[0.569814623064877, 'tanh'], [0.8448147666569815, 'tanh'], [0.09883656670056751, 'tanh'], ['linear'], ['linear'], ['adam']]\n",
            "Loser: \n",
            "[[0.057245223880398766, 'relu'], [0.20338296344634088, 'tanh'], [0.7221576026348004, 'sigmoid'], ['relu'], ['tanh'], ['adam']]\n",
            "Child: \n",
            "[[0.46888724265769843, 'sigmoid'], [0.6342333441738927, 'softmax'], [0.668916465188272, 'relu'], ['relu'], ['sigmoid'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.2194 - val_loss: 0.2193\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.2189 - val_loss: 0.2188\n",
            "__________________\n",
            "Generation: 24\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0705 - val_loss: 0.0582\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0538 - val_loss: 0.0520\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0497 - val_loss: 0.0400\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0376 - val_loss: 0.0375\n",
            "Winner: \n",
            "[[0.6198159910348582, 'linear'], [0.5590531582864904, 'sigmoid'], [0.5232156490604428, 'linear'], ['linear'], ['linear'], ['adam']]\n",
            "Loser: \n",
            "[[0.4444184866420996, 'relu'], [0.20584139040361293, 'linear'], [0.35347900620237627, 'tanh'], ['relu'], ['sigmoid'], ['adam']]\n",
            "Child: \n",
            "[[0.7524446938482375, 'sigmoid'], [0.29368023265541743, 'linear'], [0.907506450585388, 'sigmoid'], ['linear'], ['sigmoid'], ['adam']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0642 - val_loss: 0.0570\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0515 - val_loss: 0.0517\n",
            "__________________\n",
            "Generation: 25\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.2193 - val_loss: 0.2188\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.2181 - val_loss: 0.2176\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.2194 - val_loss: 0.2193\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.2189 - val_loss: 0.2188\n",
            "Winner: \n",
            "[[0.372314449263103, 'tanh'], [0.7153000479180676, 'linear'], [0.43873386860927377, 'relu'], ['sigmoid'], ['sigmoid'], ['sgd']]\n",
            "Loser: \n",
            "[[0.46888724265769843, 'sigmoid'], [0.6342333441738927, 'softmax'], [0.668916465188272, 'relu'], ['relu'], ['sigmoid'], ['sgd']]\n",
            "Child: \n",
            "[[0.1292857717970396, 'linear'], [0.5633939518561157, 'sigmoid'], [0.3779753665264066, 'sigmoid'], ['tanh'], ['relu'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.1130 - val_loss: 0.0947\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0855 - val_loss: 0.0854\n",
            "__________________\n",
            "Generation: 26\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0674 - val_loss: 0.0585\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0564 - val_loss: 0.0583\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0601 - val_loss: 0.0586\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0567 - val_loss: 0.0585\n",
            "Winner: \n",
            "[[0.7376730721700954, 'tanh'], [0.3856871162036182, 'sigmoid'], [0.24155751394996772, 'softmax'], ['tanh'], ['linear'], ['adam']]\n",
            "Loser: \n",
            "[[0.6902528490744793, 'tanh'], [0.35458497867970773, 'sigmoid'], [0.35274975460726166, 'softmax'], ['linear'], ['sigmoid'], ['adam']]\n",
            "Child: \n",
            "[[0.4090595337713976, 'sigmoid'], [0.34300394048908, 'sigmoid'], [0.5922674124230177, 'relu'], ['tanh'], ['relu'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.1035 - val_loss: 0.0939\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0848 - val_loss: 0.0837\n",
            "__________________\n",
            "Generation: 27\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.2203 - val_loss: 0.2150\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.2098 - val_loss: 0.2049\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.1056 - val_loss: 0.0947\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0853 - val_loss: 0.0837\n",
            "Winner: \n",
            "[[0.4090595337713976, 'sigmoid'], [0.34300394048908, 'sigmoid'], [0.5922674124230177, 'relu'], ['tanh'], ['relu'], ['sgd']]\n",
            "Loser: \n",
            "[[0.10922897397984355, 'softmax'], [0.46413907021136735, 'linear'], [0.29905091241460025, 'sigmoid'], ['tanh'], ['sigmoid'], ['sgd']]\n",
            "Child: \n",
            "[[0.9892193913520414, 'relu'], [0.1362478503181247, 'tanh'], [0.6688606079538288, 'softmax'], ['sigmoid'], ['softmax'], ['adam']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0983 - val_loss: 0.1013\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0972 - val_loss: 0.1013\n",
            "__________________\n",
            "Generation: 28\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Winner: \n",
            "[[0.416494741847798, 'softmax'], [0.016140423345351373, 'relu'], [0.12672924263977559, 'linear'], ['sigmoid'], ['softmax'], ['sgd']]\n",
            "Loser: \n",
            "[[0.8140387296972396, 'relu'], [0.0031451029522431284, 'relu'], [0.23271340947689834, 'softmax'], ['tanh'], ['softmax'], ['sgd']]\n",
            "Child: \n",
            "[[0.8666468126015634, 'linear'], [0.8181269940756618, 'softmax'], [0.962854353686142, 'linear'], ['tanh'], ['softmax'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "__________________\n",
            "Generation: 29\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0958 - val_loss: 0.0995\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0952 - val_loss: 0.0994\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Winner: \n",
            "[[0.5066952180295587, 'sigmoid'], [0.8532374791648694, 'linear'], [0.4097462670709051, 'linear'], ['tanh'], ['softmax'], ['adam']]\n",
            "Loser: \n",
            "[[0.8897384317892375, 'sigmoid'], [0.5095987066116655, 'relu'], [0.3916185428952589, 'linear'], ['softmax'], ['softmax'], ['sgd']]\n",
            "Child: \n",
            "[[0.021694009116321022, 'tanh'], [0.16814531158412405, 'softmax'], [0.03472053349341975, 'relu'], ['tanh'], ['sigmoid'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2193 - val_loss: 0.2191\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.2188 - val_loss: 0.2186\n",
            "__________________\n",
            "Generation: 30\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 6ms/step - loss: 0.0636 - val_loss: 0.0578\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0535 - val_loss: 0.0523\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Winner: \n",
            "[[0.7524446938482375, 'sigmoid'], [0.29368023265541743, 'linear'], [0.907506450585388, 'sigmoid'], ['linear'], ['sigmoid'], ['adam']]\n",
            "Loser: \n",
            "[[0.46854394950240597, 'sigmoid'], [0.1938376376713814, 'softmax'], [0.21640028600754113, 'softmax'], ['tanh'], ['softmax'], ['sgd']]\n",
            "Child: \n",
            "[[0.5764952407071836, 'relu'], [0.7101978391754529, 'linear'], [0.9664167369977651, 'relu'], ['softmax'], ['tanh'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0987 - val_loss: 0.1002\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0939 - val_loss: 0.0957\n",
            "__________________\n",
            "Generation: 31\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.1228 - val_loss: 0.1097\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0976 - val_loss: 0.0952\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2194 - val_loss: 0.2193\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2189 - val_loss: 0.2188\n",
            "Winner: \n",
            "[[0.5762952169700479, 'sigmoid'], [0.15615652611684716, 'linear'], [0.9951994531165488, 'sigmoid'], ['softmax'], ['tanh'], ['sgd']]\n",
            "Loser: \n",
            "[[0.021694009116321022, 'tanh'], [0.16814531158412405, 'softmax'], [0.03472053349341975, 'relu'], ['tanh'], ['sigmoid'], ['sgd']]\n",
            "Child: \n",
            "[[0.12249355933658712, 'tanh'], [0.6533060332390801, 'tanh'], [0.3045523642474117, 'sigmoid'], ['tanh'], ['tanh'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.1199 - val_loss: 0.0960\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0805 - val_loss: 0.0750\n",
            "__________________\n",
            "Generation: 32\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 7ms/step - loss: 0.0958 - val_loss: 0.0994\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0951 - val_loss: 0.0993\n",
            "Winner: \n",
            "[[0.5066952180295587, 'sigmoid'], [0.8532374791648694, 'linear'], [0.4097462670709051, 'linear'], ['tanh'], ['softmax'], ['adam']]\n",
            "Loser: \n",
            "[[0.416494741847798, 'softmax'], [0.016140423345351373, 'relu'], [0.12672924263977559, 'linear'], ['sigmoid'], ['softmax'], ['sgd']]\n",
            "Child: \n",
            "[[0.21792960009471962, 'relu'], [0.4022829479361023, 'sigmoid'], [0.2911076132416178, 'softmax'], ['linear'], ['linear'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.1576 - val_loss: 0.1079\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0834 - val_loss: 0.0717\n",
            "__________________\n",
            "Generation: 33\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.1074 - val_loss: 0.0870\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0781 - val_loss: 0.0772\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0599 - val_loss: 0.0587\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0566 - val_loss: 0.0584\n",
            "Winner: \n",
            "[[0.7376730721700954, 'tanh'], [0.3856871162036182, 'sigmoid'], [0.24155751394996772, 'softmax'], ['tanh'], ['linear'], ['adam']]\n",
            "Loser: \n",
            "[[0.1292857717970396, 'linear'], [0.5633939518561157, 'sigmoid'], [0.3779753665264066, 'sigmoid'], ['tanh'], ['relu'], ['sgd']]\n",
            "Child: \n",
            "[[0.914421685827176, 'sigmoid'], [0.8517024877770334, 'linear'], [0.5227929301181367, 'linear'], ['tanh'], ['relu'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 7ms/step - loss: 0.0935 - val_loss: 0.0946\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0875 - val_loss: 0.0873\n",
            "__________________\n",
            "Generation: 34\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0923 - val_loss: 0.0921\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0847 - val_loss: 0.0836\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0605 - val_loss: 0.0585\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0567 - val_loss: 0.0585\n",
            "Winner: \n",
            "[[0.7376730721700954, 'tanh'], [0.3856871162036182, 'sigmoid'], [0.24155751394996772, 'softmax'], ['tanh'], ['linear'], ['adam']]\n",
            "Loser: \n",
            "[[0.914421685827176, 'sigmoid'], [0.8517024877770334, 'linear'], [0.5227929301181367, 'linear'], ['tanh'], ['relu'], ['sgd']]\n",
            "Child: \n",
            "[[0.6778968064066961, 'sigmoid'], [0.1443183984764661, 'linear'], [0.05704913024382274, 'relu'], ['relu'], ['sigmoid'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2201 - val_loss: 0.2196\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2188 - val_loss: 0.2183\n",
            "__________________\n",
            "Generation: 35\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0594 - val_loss: 0.0580\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0534 - val_loss: 0.0524\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0959 - val_loss: 0.0995\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0952 - val_loss: 0.0994\n",
            "Winner: \n",
            "[[0.9111233110350488, 'sigmoid'], [0.45829621813402954, 'sigmoid'], [0.8352668185787894, 'sigmoid'], ['sigmoid'], ['linear'], ['adam']]\n",
            "Loser: \n",
            "[[0.5066952180295587, 'sigmoid'], [0.8532374791648694, 'linear'], [0.4097462670709051, 'linear'], ['tanh'], ['softmax'], ['adam']]\n",
            "Child: \n",
            "[[0.8827594759250352, 'tanh'], [0.048422523309281984, 'tanh'], [0.13214109011354547, 'sigmoid'], ['sigmoid'], ['tanh'], ['adam']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0592 - val_loss: 0.0536\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0471 - val_loss: 0.0443\n",
            "__________________\n",
            "Generation: 36\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0597 - val_loss: 0.0516\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0457 - val_loss: 0.0445\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 6ms/step - loss: 0.0443 - val_loss: 0.0400\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0389 - val_loss: 0.0396\n",
            "Winner: \n",
            "[[0.569814623064877, 'tanh'], [0.8448147666569815, 'tanh'], [0.09883656670056751, 'tanh'], ['linear'], ['linear'], ['adam']]\n",
            "Loser: \n",
            "[[0.8827594759250352, 'tanh'], [0.048422523309281984, 'tanh'], [0.13214109011354547, 'sigmoid'], ['sigmoid'], ['tanh'], ['adam']]\n",
            "Child: \n",
            "[[0.2831713607776616, 'sigmoid'], [0.9381785425505179, 'softmax'], [0.013771717177347043, 'sigmoid'], ['softmax'], ['tanh'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0996 - val_loss: 0.1028\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0975 - val_loss: 0.1007\n",
            "__________________\n",
            "Generation: 37\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 4s 8ms/step - loss: 0.0974 - val_loss: 0.1013\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0962 - val_loss: 0.0999\n",
            "Winner: \n",
            "[[0.42945519286572775, 'softmax'], [0.3839340417156384, 'sigmoid'], [0.5920513940878305, 'linear'], ['relu'], ['softmax'], ['adam']]\n",
            "Loser: \n",
            "[[0.8666468126015634, 'linear'], [0.8181269940756618, 'softmax'], [0.962854353686142, 'linear'], ['tanh'], ['softmax'], ['sgd']]\n",
            "Child: \n",
            "[[0.512384019413943, 'linear'], [0.14314981299757312, 'linear'], [0.6904208395895556, 'tanh'], ['tanh'], ['softmax'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "__________________\n",
            "Generation: 38\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.1506 - val_loss: 0.1044\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0816 - val_loss: 0.0707\n",
            "Winner: \n",
            "[[0.512384019413943, 'linear'], [0.14314981299757312, 'linear'], [0.6904208395895556, 'tanh'], ['tanh'], ['softmax'], ['sgd']]\n",
            "Loser: \n",
            "[[0.21792960009471962, 'relu'], [0.4022829479361023, 'sigmoid'], [0.2911076132416178, 'softmax'], ['linear'], ['linear'], ['sgd']]\n",
            "Child: \n",
            "[[0.12544989542704954, 'sigmoid'], [0.41166045283883657, 'sigmoid'], [0.6603634776576359, 'linear'], ['softmax'], ['linear'], ['adam']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0498 - val_loss: 0.0394\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.0374 - val_loss: 0.0370\n",
            "[[32, 'sigmoid'], [13, 'sigmoid'], [9, 'linear'], ['softmax'], ['linear'], ['adam']]\n",
            "-0.049826886504888535\n",
            "__________________\n",
            "Generation: 39\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0502 - val_loss: 0.0404\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0382 - val_loss: 0.0381\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0591 - val_loss: 0.0579\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.0528 - val_loss: 0.0521\n",
            "Winner: \n",
            "[[0.12544989542704954, 'sigmoid'], [0.41166045283883657, 'sigmoid'], [0.6603634776576359, 'linear'], ['softmax'], ['linear'], ['adam']]\n",
            "Loser: \n",
            "[[0.9111233110350488, 'sigmoid'], [0.45829621813402954, 'sigmoid'], [0.8352668185787894, 'sigmoid'], ['sigmoid'], ['linear'], ['adam']]\n",
            "Child: \n",
            "[[0.7666922606540987, 'softmax'], [0.5370530453476611, 'linear'], [0.5871127243570878, 'linear'], ['tanh'], ['softmax'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "__________________\n",
            "Generation: 40\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.2187 - val_loss: 0.2182\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.2174 - val_loss: 0.2169\n",
            "Winner: \n",
            "[[0.7666922606540987, 'softmax'], [0.5370530453476611, 'linear'], [0.5871127243570878, 'linear'], ['tanh'], ['softmax'], ['sgd']]\n",
            "Loser: \n",
            "[[0.372314449263103, 'tanh'], [0.7153000479180676, 'linear'], [0.43873386860927377, 'relu'], ['sigmoid'], ['sigmoid'], ['sgd']]\n",
            "Child: \n",
            "[[0.6071943542230277, 'softmax'], [0.8349384059065131, 'linear'], [0.5075192135708624, 'sigmoid'], ['linear'], ['relu'], ['adam']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 7ms/step - loss: 0.0657 - val_loss: 0.0593\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0505 - val_loss: 0.0508\n",
            "__________________\n",
            "Generation: 41\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0443 - val_loss: 0.0376\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0315 - val_loss: 0.0300\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.2201 - val_loss: 0.2195\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2188 - val_loss: 0.2184\n",
            "Winner: \n",
            "[[0.14734891885940837, 'linear'], [0.8668511904168803, 'relu'], [0.625084948095747, 'relu'], ['relu'], ['linear'], ['adam']]\n",
            "Loser: \n",
            "[[0.6778968064066961, 'sigmoid'], [0.1443183984764661, 'linear'], [0.05704913024382274, 'relu'], ['relu'], ['sigmoid'], ['sgd']]\n",
            "Child: \n",
            "[[0.6267668020001717, 'softmax'], [0.24305194690690946, 'softmax'], [0.47329143194495604, 'sigmoid'], ['tanh'], ['sigmoid'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.2192 - val_loss: 0.2191\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.2187 - val_loss: 0.2186\n",
            "__________________\n",
            "Generation: 42\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0601 - val_loss: 0.0586\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0567 - val_loss: 0.0584\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0986 - val_loss: 0.0995\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0927 - val_loss: 0.0940\n",
            "Winner: \n",
            "[[0.7376730721700954, 'tanh'], [0.3856871162036182, 'sigmoid'], [0.24155751394996772, 'softmax'], ['tanh'], ['linear'], ['adam']]\n",
            "Loser: \n",
            "[[0.5764952407071836, 'relu'], [0.7101978391754529, 'linear'], [0.9664167369977651, 'relu'], ['softmax'], ['tanh'], ['sgd']]\n",
            "Child: \n",
            "[[0.14648538118669685, 'softmax'], [0.6489160368156419, 'relu'], [0.43646250883541826, 'linear'], ['softmax'], ['tanh'], ['adam']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0393 - val_loss: 0.0329\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0309 - val_loss: 0.0310\n",
            "[[38, 'softmax'], [25, 'relu'], [11, 'linear'], ['softmax'], ['tanh'], ['adam']]\n",
            "-0.03934888169169426\n",
            "__________________\n",
            "Generation: 43\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 6ms/step - loss: 0.0490 - val_loss: 0.0395\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0368 - val_loss: 0.0363\n",
            "Winner: \n",
            "[[0.6198159910348582, 'linear'], [0.5590531582864904, 'sigmoid'], [0.5232156490604428, 'linear'], ['linear'], ['linear'], ['adam']]\n",
            "Loser: \n",
            "[[0.512384019413943, 'linear'], [0.14314981299757312, 'linear'], [0.6904208395895556, 'tanh'], ['tanh'], ['softmax'], ['sgd']]\n",
            "Child: \n",
            "[[0.06670400127567278, 'tanh'], [0.9248402075573866, 'softmax'], [0.863528102337226, 'relu'], ['tanh'], ['tanh'], ['adam']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 5s 14ms/step - loss: 0.0654 - val_loss: 0.0551\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0511 - val_loss: 0.0512\n",
            "__________________\n",
            "Generation: 44\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0974 - val_loss: 0.1012\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.0964 - val_loss: 0.1001\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0997 - val_loss: 0.1029\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0977 - val_loss: 0.1008\n",
            "Winner: \n",
            "[[0.42945519286572775, 'softmax'], [0.3839340417156384, 'sigmoid'], [0.5920513940878305, 'linear'], ['relu'], ['softmax'], ['adam']]\n",
            "Loser: \n",
            "[[0.2831713607776616, 'sigmoid'], [0.9381785425505179, 'softmax'], [0.013771717177347043, 'sigmoid'], ['softmax'], ['tanh'], ['sgd']]\n",
            "Child: \n",
            "[[0.8319621500859595, 'softmax'], [0.21526429494863275, 'sigmoid'], [0.0014305470796508457, 'sigmoid'], ['linear'], ['tanh'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.1418 - val_loss: 0.1232\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.1040 - val_loss: 0.0939\n",
            "__________________\n",
            "Generation: 45\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 6ms/step - loss: 0.0974 - val_loss: 0.1013\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0965 - val_loss: 0.1004\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 7ms/step - loss: 0.0436 - val_loss: 0.0402\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0389 - val_loss: 0.0396\n",
            "Winner: \n",
            "[[0.569814623064877, 'tanh'], [0.8448147666569815, 'tanh'], [0.09883656670056751, 'tanh'], ['linear'], ['linear'], ['adam']]\n",
            "Loser: \n",
            "[[0.42945519286572775, 'softmax'], [0.3839340417156384, 'sigmoid'], [0.5920513940878305, 'linear'], ['relu'], ['softmax'], ['adam']]\n",
            "Child: \n",
            "[[0.4426912826157504, 'tanh'], [0.3377186292104849, 'softmax'], [0.37991486178823497, 'sigmoid'], ['sigmoid'], ['relu'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0994 - val_loss: 0.1032\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0985 - val_loss: 0.1023\n",
            "__________________\n",
            "Generation: 46\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0653 - val_loss: 0.0556\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0504 - val_loss: 0.0511\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.1180 - val_loss: 0.0959\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0812 - val_loss: 0.0756\n",
            "Winner: \n",
            "[[0.6071943542230277, 'softmax'], [0.8349384059065131, 'linear'], [0.5075192135708624, 'sigmoid'], ['linear'], ['relu'], ['adam']]\n",
            "Loser: \n",
            "[[0.12249355933658712, 'tanh'], [0.6533060332390801, 'tanh'], [0.3045523642474117, 'sigmoid'], ['tanh'], ['tanh'], ['sgd']]\n",
            "Child: \n",
            "[[0.4156144386452272, 'tanh'], [0.4260788139254963, 'tanh'], [0.02258454650800923, 'relu'], ['tanh'], ['linear'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0998 - val_loss: 0.1018\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0960 - val_loss: 0.0984\n",
            "__________________\n",
            "Generation: 47\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0982 - val_loss: 0.1013\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0972 - val_loss: 0.1013\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0656 - val_loss: 0.0567\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0517 - val_loss: 0.0521\n",
            "Winner: \n",
            "[[0.06670400127567278, 'tanh'], [0.9248402075573866, 'softmax'], [0.863528102337226, 'relu'], ['tanh'], ['tanh'], ['adam']]\n",
            "Loser: \n",
            "[[0.9892193913520414, 'relu'], [0.1362478503181247, 'tanh'], [0.6688606079538288, 'softmax'], ['sigmoid'], ['softmax'], ['adam']]\n",
            "Child: \n",
            "[[0.9699998233795569, 'softmax'], [0.4421759037095453, 'tanh'], [0.1943194616753452, 'tanh'], ['relu'], ['tanh'], ['adam']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0451 - val_loss: 0.0405\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0392 - val_loss: 0.0398\n",
            "__________________\n",
            "Generation: 48\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.1018 - val_loss: 0.1027\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0966 - val_loss: 0.0990\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.2192 - val_loss: 0.2190\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.2187 - val_loss: 0.2185\n",
            "Winner: \n",
            "[[0.4156144386452272, 'tanh'], [0.4260788139254963, 'tanh'], [0.02258454650800923, 'relu'], ['tanh'], ['linear'], ['sgd']]\n",
            "Loser: \n",
            "[[0.6267668020001717, 'softmax'], [0.24305194690690946, 'softmax'], [0.47329143194495604, 'sigmoid'], ['tanh'], ['sigmoid'], ['sgd']]\n",
            "Child: \n",
            "[[0.07239259482539318, 'relu'], [0.7062745973971906, 'tanh'], [0.8917064014342403, 'relu'], ['tanh'], ['softmax'], ['adam']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 7ms/step - loss: 0.0969 - val_loss: 0.1000\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0955 - val_loss: 0.0995\n",
            "__________________\n",
            "Generation: 49\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1019 - val_loss: 0.1030\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0967 - val_loss: 0.0991\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 5ms/step - loss: 0.1003 - val_loss: 0.1033\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0981 - val_loss: 0.1011\n",
            "Winner: \n",
            "[[0.8633232522497706, 'sigmoid'], [0.08632177387565998, 'softmax'], [0.5324302641552852, 'tanh'], ['sigmoid'], ['linear'], ['sgd']]\n",
            "Loser: \n",
            "[[0.4156144386452272, 'tanh'], [0.4260788139254963, 'tanh'], [0.02258454650800923, 'relu'], ['tanh'], ['linear'], ['sgd']]\n",
            "Child: \n",
            "[[0.8881292317902703, 'softmax'], [0.7274963239524301, 'tanh'], [0.6149603917485709, 'sigmoid'], ['linear'], ['relu'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0961 - val_loss: 0.0887\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0831 - val_loss: 0.0848\n",
            "__________________\n",
            "Generation: 50\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 7ms/step - loss: 0.0441 - val_loss: 0.0401\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0389 - val_loss: 0.0397\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.2192 - val_loss: 0.2190\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.2184 - val_loss: 0.2181\n",
            "Winner: \n",
            "[[0.569814623064877, 'tanh'], [0.8448147666569815, 'tanh'], [0.09883656670056751, 'tanh'], ['linear'], ['linear'], ['adam']]\n",
            "Loser: \n",
            "[[0.9694988990816781, 'linear'], [0.30419274846329925, 'relu'], [0.0771577187862783, 'tanh'], ['linear'], ['sigmoid'], ['sgd']]\n",
            "Child: \n",
            "[[0.06718655096716741, 'softmax'], [0.0810701236708482, 'softmax'], [0.4228862048983367, 'sigmoid'], ['tanh'], ['linear'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0998 - val_loss: 0.1028\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0976 - val_loss: 0.1006\n",
            "__________________\n",
            "Generation: 51\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 6ms/step - loss: 0.0438 - val_loss: 0.0403\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0390 - val_loss: 0.0397\n",
            "Winner: \n",
            "[[0.569814623064877, 'tanh'], [0.8448147666569815, 'tanh'], [0.09883656670056751, 'tanh'], ['linear'], ['linear'], ['adam']]\n",
            "Loser: \n",
            "[[0.7666922606540987, 'softmax'], [0.5370530453476611, 'linear'], [0.5871127243570878, 'linear'], ['tanh'], ['softmax'], ['sgd']]\n",
            "Child: \n",
            "[[0.5380622704214664, 'sigmoid'], [0.6612472241653883, 'linear'], [0.7303843984040891, 'linear'], ['linear'], ['linear'], ['adam']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0422 - val_loss: 0.0399\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0388 - val_loss: 0.0397\n",
            "__________________\n",
            "Generation: 52\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 7ms/step - loss: 0.0966 - val_loss: 0.1000\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0956 - val_loss: 0.0996\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 7ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Winner: \n",
            "[[0.07239259482539318, 'relu'], [0.7062745973971906, 'tanh'], [0.8917064014342403, 'relu'], ['tanh'], ['softmax'], ['adam']]\n",
            "Loser: \n",
            "[[0.24413699957055524, 'relu'], [0.5197692674130492, 'linear'], [0.6488057524583702, 'softmax'], ['relu'], ['softmax'], ['sgd']]\n",
            "Child: \n",
            "[[0.7959160277915476, 'relu'], [0.17282173464669737, 'linear'], [0.19152525422124178, 'softmax'], ['tanh'], ['relu'], ['adam']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0755 - val_loss: 0.0750\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0690 - val_loss: 0.0682\n",
            "__________________\n",
            "Generation: 53\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 4ms/step - loss: 0.1217 - val_loss: 0.1062\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0935 - val_loss: 0.0900\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0442 - val_loss: 0.0402\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0388 - val_loss: 0.0395\n",
            "Winner: \n",
            "[[0.569814623064877, 'tanh'], [0.8448147666569815, 'tanh'], [0.09883656670056751, 'tanh'], ['linear'], ['linear'], ['adam']]\n",
            "Loser: \n",
            "[[0.5762952169700479, 'sigmoid'], [0.15615652611684716, 'linear'], [0.9951994531165488, 'sigmoid'], ['softmax'], ['tanh'], ['sgd']]\n",
            "Child: \n",
            "[[0.6596530757423522, 'relu'], [0.06099489276604286, 'sigmoid'], [0.2267030902005538, 'linear'], ['relu'], ['linear'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 3ms/step - loss: 0.1186 - val_loss: 0.1150\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.1051 - val_loss: 0.1030\n",
            "__________________\n",
            "Generation: 54\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.1076 - val_loss: 0.0971\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0878 - val_loss: 0.0864\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0598 - val_loss: 0.0586\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0566 - val_loss: 0.0585\n",
            "Winner: \n",
            "[[0.7376730721700954, 'tanh'], [0.3856871162036182, 'sigmoid'], [0.24155751394996772, 'softmax'], ['tanh'], ['linear'], ['adam']]\n",
            "Loser: \n",
            "[[0.4090595337713976, 'sigmoid'], [0.34300394048908, 'sigmoid'], [0.5922674124230177, 'relu'], ['tanh'], ['relu'], ['sgd']]\n",
            "Child: \n",
            "[[0.11548116739502856, 'tanh'], [0.18468312299590683, 'relu'], [0.5628822064913049, 'linear'], ['relu'], ['relu'], ['adam']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0496 - val_loss: 0.0409\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0361 - val_loss: 0.0355\n",
            "__________________\n",
            "Generation: 55\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0456 - val_loss: 0.0407\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0393 - val_loss: 0.0398\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0764 - val_loss: 0.0743\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0694 - val_loss: 0.0707\n",
            "Winner: \n",
            "[[0.9699998233795569, 'softmax'], [0.4421759037095453, 'tanh'], [0.1943194616753452, 'tanh'], ['relu'], ['tanh'], ['adam']]\n",
            "Loser: \n",
            "[[0.7959160277915476, 'relu'], [0.17282173464669737, 'linear'], [0.19152525422124178, 'softmax'], ['tanh'], ['relu'], ['adam']]\n",
            "Child: \n",
            "[[0.2733408000448573, 'linear'], [0.7801165277667977, 'tanh'], [0.5294921871642879, 'softmax'], ['sigmoid'], ['tanh'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 7ms/step - loss: 0.0987 - val_loss: 0.1010\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0951 - val_loss: 0.0975\n",
            "__________________\n",
            "Generation: 56\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0486 - val_loss: 0.0395\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0368 - val_loss: 0.0361\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1420 - val_loss: 0.1231\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1039 - val_loss: 0.0937\n",
            "Winner: \n",
            "[[0.6198159910348582, 'linear'], [0.5590531582864904, 'sigmoid'], [0.5232156490604428, 'linear'], ['linear'], ['linear'], ['adam']]\n",
            "Loser: \n",
            "[[0.8319621500859595, 'softmax'], [0.21526429494863275, 'sigmoid'], [0.0014305470796508457, 'sigmoid'], ['linear'], ['tanh'], ['sgd']]\n",
            "Child: \n",
            "[[0.6077319415753307, 'linear'], [0.0030563451175711354, 'softmax'], [0.6352040193491875, 'sigmoid'], ['linear'], ['tanh'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1052 - val_loss: 0.1070\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1008 - val_loss: 0.1028\n",
            "__________________\n",
            "Generation: 57\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0910 - val_loss: 0.0852\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0798 - val_loss: 0.0816\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0506 - val_loss: 0.0438\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0400 - val_loss: 0.0381\n",
            "Winner: \n",
            "[[0.11548116739502856, 'tanh'], [0.18468312299590683, 'relu'], [0.5628822064913049, 'linear'], ['relu'], ['relu'], ['adam']]\n",
            "Loser: \n",
            "[[0.8881292317902703, 'softmax'], [0.7274963239524301, 'tanh'], [0.6149603917485709, 'sigmoid'], ['linear'], ['relu'], ['sgd']]\n",
            "Child: \n",
            "[[0.42200405231683924, 'tanh'], [0.5379303907943755, 'linear'], [0.052018658280332364, 'relu'], ['softmax'], ['softmax'], ['adam']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 7ms/step - loss: 0.0969 - val_loss: 0.1003\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0959 - val_loss: 0.0999\n",
            "__________________\n",
            "Generation: 58\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.1285 - val_loss: 0.1238\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.1125 - val_loss: 0.1097\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0438 - val_loss: 0.0403\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0388 - val_loss: 0.0396\n",
            "Winner: \n",
            "[[0.569814623064877, 'tanh'], [0.8448147666569815, 'tanh'], [0.09883656670056751, 'tanh'], ['linear'], ['linear'], ['adam']]\n",
            "Loser: \n",
            "[[0.6596530757423522, 'relu'], [0.06099489276604286, 'sigmoid'], [0.2267030902005538, 'linear'], ['relu'], ['linear'], ['sgd']]\n",
            "Child: \n",
            "[[0.6817237635310908, 'tanh'], [0.7300967933345416, 'tanh'], [0.09675468925230213, 'tanh'], ['relu'], ['softmax'], ['adam']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 6ms/step - loss: 0.0974 - val_loss: 0.1008\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0960 - val_loss: 0.0998\n",
            "__________________\n",
            "Generation: 59\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0975 - val_loss: 0.1012\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0967 - val_loss: 0.1006\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 7ms/step - loss: 0.0969 - val_loss: 0.1000\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0956 - val_loss: 0.0996\n",
            "Winner: \n",
            "[[0.07239259482539318, 'relu'], [0.7062745973971906, 'tanh'], [0.8917064014342403, 'relu'], ['tanh'], ['softmax'], ['adam']]\n",
            "Loser: \n",
            "[[0.42200405231683924, 'tanh'], [0.5379303907943755, 'linear'], [0.052018658280332364, 'relu'], ['softmax'], ['softmax'], ['adam']]\n",
            "Child: \n",
            "[[0.9501626872306544, 'softmax'], [0.03782411737233382, 'tanh'], [0.6989668363081517, 'softmax'], ['linear'], ['linear'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.1002 - val_loss: 0.1029\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0975 - val_loss: 0.1003\n",
            "__________________\n",
            "Generation: 60\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0456 - val_loss: 0.0404\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.0391 - val_loss: 0.0397\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 5ms/step - loss: 0.0491 - val_loss: 0.0400\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0354 - val_loss: 0.0343\n",
            "Winner: \n",
            "[[0.9699998233795569, 'softmax'], [0.4421759037095453, 'tanh'], [0.1943194616753452, 'tanh'], ['relu'], ['tanh'], ['adam']]\n",
            "Loser: \n",
            "[[0.11548116739502856, 'tanh'], [0.18468312299590683, 'relu'], [0.5628822064913049, 'linear'], ['relu'], ['relu'], ['adam']]\n",
            "Child: \n",
            "[[0.6714161518927767, 'tanh'], [0.4448673352299575, 'relu'], [0.5990595323672131, 'softmax'], ['relu'], ['softmax'], ['adam']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0983 - val_loss: 0.1013\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0972 - val_loss: 0.1013\n",
            "__________________\n",
            "Generation: 61\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0993 - val_loss: 0.1023\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0971 - val_loss: 0.1002\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 4s 9ms/step - loss: 0.0983 - val_loss: 0.1013\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0972 - val_loss: 0.1013\n",
            "Winner: \n",
            "[[0.6714161518927767, 'tanh'], [0.4448673352299575, 'relu'], [0.5990595323672131, 'softmax'], ['relu'], ['softmax'], ['adam']]\n",
            "Loser: \n",
            "[[0.06718655096716741, 'softmax'], [0.0810701236708482, 'softmax'], [0.4228862048983367, 'sigmoid'], ['tanh'], ['linear'], ['sgd']]\n",
            "Child: \n",
            "[[0.7863975891412296, 'linear'], [0.3304862693819449, 'relu'], [0.8405694959821457, 'linear'], ['sigmoid'], ['sigmoid'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.2185 - val_loss: 0.2180\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.2173 - val_loss: 0.2166\n",
            "__________________\n",
            "Generation: 62\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1072 - val_loss: 0.1088\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1024 - val_loss: 0.1042\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.0444 - val_loss: 0.0394\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0359 - val_loss: 0.0359\n",
            "Winner: \n",
            "[[0.14734891885940837, 'linear'], [0.8668511904168803, 'relu'], [0.625084948095747, 'relu'], ['relu'], ['linear'], ['adam']]\n",
            "Loser: \n",
            "[[0.6077319415753307, 'linear'], [0.0030563451175711354, 'softmax'], [0.6352040193491875, 'sigmoid'], ['linear'], ['tanh'], ['sgd']]\n",
            "Child: \n",
            "[[0.17858238533569315, 'tanh'], [0.7105189143615694, 'softmax'], [0.21120172410128812, 'relu'], ['sigmoid'], ['sigmoid'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.2193 - val_loss: 0.2192\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.2188 - val_loss: 0.2187\n",
            "__________________\n",
            "Generation: 63\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0470 - val_loss: 0.0407\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0393 - val_loss: 0.0399\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0598 - val_loss: 0.0588\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0567 - val_loss: 0.0583\n",
            "Winner: \n",
            "[[0.9699998233795569, 'softmax'], [0.4421759037095453, 'tanh'], [0.1943194616753452, 'tanh'], ['relu'], ['tanh'], ['adam']]\n",
            "Loser: \n",
            "[[0.7376730721700954, 'tanh'], [0.3856871162036182, 'sigmoid'], [0.24155751394996772, 'softmax'], ['tanh'], ['linear'], ['adam']]\n",
            "Child: \n",
            "[[0.02998725627237897, 'sigmoid'], [0.5105054021663087, 'softmax'], [0.6054155892112355, 'sigmoid'], ['linear'], ['tanh'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0996 - val_loss: 0.1027\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0975 - val_loss: 0.1006\n",
            "__________________\n",
            "Generation: 64\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0972 - val_loss: 0.1004\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0957 - val_loss: 0.0997\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0433 - val_loss: 0.0383\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0338 - val_loss: 0.0320\n",
            "Winner: \n",
            "[[0.14734891885940837, 'linear'], [0.8668511904168803, 'relu'], [0.625084948095747, 'relu'], ['relu'], ['linear'], ['adam']]\n",
            "Loser: \n",
            "[[0.6817237635310908, 'tanh'], [0.7300967933345416, 'tanh'], [0.09675468925230213, 'tanh'], ['relu'], ['softmax'], ['adam']]\n",
            "Child: \n",
            "[[0.6327544451791836, 'sigmoid'], [0.5432473572474722, 'linear'], [0.7152111416735459, 'tanh'], ['softmax'], ['linear'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.1009 - val_loss: 0.1011\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0939 - val_loss: 0.0948\n",
            "__________________\n",
            "Generation: 65\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 4s 9ms/step - loss: 0.0417 - val_loss: 0.0400\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0387 - val_loss: 0.0396\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 7ms/step - loss: 0.2194 - val_loss: 0.2193\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.2189 - val_loss: 0.2188\n",
            "Winner: \n",
            "[[0.5380622704214664, 'sigmoid'], [0.6612472241653883, 'linear'], [0.7303843984040891, 'linear'], ['linear'], ['linear'], ['adam']]\n",
            "Loser: \n",
            "[[0.17858238533569315, 'tanh'], [0.7105189143615694, 'softmax'], [0.21120172410128812, 'relu'], ['sigmoid'], ['sigmoid'], ['sgd']]\n",
            "Child: \n",
            "[[0.7972524082377281, 'linear'], [0.6151658684152892, 'tanh'], [0.03943394329032357, 'tanh'], ['sigmoid'], ['linear'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.1029 - val_loss: 0.1036\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0964 - val_loss: 0.0972\n",
            "__________________\n",
            "Generation: 66\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.1019 - val_loss: 0.1031\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0963 - val_loss: 0.0976\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0676 - val_loss: 0.0607\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0538 - val_loss: 0.0522\n",
            "Winner: \n",
            "[[0.6071943542230277, 'softmax'], [0.8349384059065131, 'linear'], [0.5075192135708624, 'sigmoid'], ['linear'], ['relu'], ['adam']]\n",
            "Loser: \n",
            "[[0.6327544451791836, 'sigmoid'], [0.5432473572474722, 'linear'], [0.7152111416735459, 'tanh'], ['softmax'], ['linear'], ['sgd']]\n",
            "Child: \n",
            "[[0.652066626556296, 'softmax'], [0.8277469204055975, 'softmax'], [0.9584768163936012, 'tanh'], ['sigmoid'], ['sigmoid'], ['adam']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1636 - val_loss: 0.1225\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.1025 - val_loss: 0.0897\n",
            "__________________\n",
            "Generation: 67\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0996 - val_loss: 0.1027\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0975 - val_loss: 0.1006\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0654 - val_loss: 0.0577\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.0522 - val_loss: 0.0522\n",
            "Winner: \n",
            "[[0.06670400127567278, 'tanh'], [0.9248402075573866, 'softmax'], [0.863528102337226, 'relu'], ['tanh'], ['tanh'], ['adam']]\n",
            "Loser: \n",
            "[[0.02998725627237897, 'sigmoid'], [0.5105054021663087, 'softmax'], [0.6054155892112355, 'sigmoid'], ['linear'], ['tanh'], ['sgd']]\n",
            "Child: \n",
            "[[0.9039151144554975, 'linear'], [0.30859465814183684, 'linear'], [0.81518774428541, 'sigmoid'], ['tanh'], ['sigmoid'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.2245 - val_loss: 0.2175\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2108 - val_loss: 0.2047\n",
            "__________________\n",
            "Generation: 68\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.2188 - val_loss: 0.2129\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.2066 - val_loss: 0.2013\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0499 - val_loss: 0.0408\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0385 - val_loss: 0.0390\n",
            "Winner: \n",
            "[[0.12544989542704954, 'sigmoid'], [0.41166045283883657, 'sigmoid'], [0.6603634776576359, 'linear'], ['softmax'], ['linear'], ['adam']]\n",
            "Loser: \n",
            "[[0.9039151144554975, 'linear'], [0.30859465814183684, 'linear'], [0.81518774428541, 'sigmoid'], ['tanh'], ['sigmoid'], ['sgd']]\n",
            "Child: \n",
            "[[0.21841876341515865, 'tanh'], [0.3898067501984548, 'sigmoid'], [0.813980083770169, 'sigmoid'], ['relu'], ['tanh'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.1408 - val_loss: 0.1069\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0854 - val_loss: 0.0745\n",
            "__________________\n",
            "Generation: 69\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0682 - val_loss: 0.0611\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0547 - val_loss: 0.0538\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.2189 - val_loss: 0.2185\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.2177 - val_loss: 0.2172\n",
            "Winner: \n",
            "[[0.6071943542230277, 'softmax'], [0.8349384059065131, 'linear'], [0.5075192135708624, 'sigmoid'], ['linear'], ['relu'], ['adam']]\n",
            "Loser: \n",
            "[[0.7863975891412296, 'linear'], [0.3304862693819449, 'relu'], [0.8405694959821457, 'linear'], ['sigmoid'], ['sigmoid'], ['sgd']]\n",
            "Child: \n",
            "[[0.3867781271591094, 'tanh'], [0.39246395127774303, 'tanh'], [0.8567027532227195, 'linear'], ['relu'], ['sigmoid'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.2190 - val_loss: 0.2180\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.2167 - val_loss: 0.2153\n",
            "__________________\n",
            "Generation: 70\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0501 - val_loss: 0.0403\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0375 - val_loss: 0.0366\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 4s 10ms/step - loss: 0.0500 - val_loss: 0.0405\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0375 - val_loss: 0.0374\n",
            "Winner: \n",
            "[[0.6198159910348582, 'linear'], [0.5590531582864904, 'sigmoid'], [0.5232156490604428, 'linear'], ['linear'], ['linear'], ['adam']]\n",
            "Loser: \n",
            "[[0.12544989542704954, 'sigmoid'], [0.41166045283883657, 'sigmoid'], [0.6603634776576359, 'linear'], ['softmax'], ['linear'], ['adam']]\n",
            "Child: \n",
            "[[0.8198100220193013, 'softmax'], [0.9205483448654188, 'sigmoid'], [0.8986108223070849, 'softmax'], ['relu'], ['softmax'], ['adam']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0973 - val_loss: 0.1013\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0972 - val_loss: 0.1013\n",
            "__________________\n",
            "Generation: 71\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 7ms/step - loss: 0.0458 - val_loss: 0.0408\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0392 - val_loss: 0.0399\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0983 - val_loss: 0.1013\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0972 - val_loss: 0.1013\n",
            "Winner: \n",
            "[[0.9699998233795569, 'softmax'], [0.4421759037095453, 'tanh'], [0.1943194616753452, 'tanh'], ['relu'], ['tanh'], ['adam']]\n",
            "Loser: \n",
            "[[0.6714161518927767, 'tanh'], [0.4448673352299575, 'relu'], [0.5990595323672131, 'softmax'], ['relu'], ['softmax'], ['adam']]\n",
            "Child: \n",
            "[[0.23013699470680316, 'sigmoid'], [0.8871454521084362, 'linear'], [0.12302044521186839, 'softmax'], ['sigmoid'], ['tanh'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0988 - val_loss: 0.1010\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0950 - val_loss: 0.0972\n",
            "__________________\n",
            "Generation: 72\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0646 - val_loss: 0.0581\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.0539 - val_loss: 0.0523\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0420 - val_loss: 0.0400\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0387 - val_loss: 0.0396\n",
            "Winner: \n",
            "[[0.5380622704214664, 'sigmoid'], [0.6612472241653883, 'linear'], [0.7303843984040891, 'linear'], ['linear'], ['linear'], ['adam']]\n",
            "Loser: \n",
            "[[0.7524446938482375, 'sigmoid'], [0.29368023265541743, 'linear'], [0.907506450585388, 'sigmoid'], ['linear'], ['sigmoid'], ['adam']]\n",
            "Child: \n",
            "[[0.8551712339238297, 'linear'], [0.2179077616581372, 'softmax'], [0.2809106066057785, 'tanh'], ['linear'], ['linear'], ['adam']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0656 - val_loss: 0.0580\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0556 - val_loss: 0.0549\n",
            "__________________\n",
            "Generation: 73\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.1697 - val_loss: 0.1262\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0981 - val_loss: 0.0823\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0659 - val_loss: 0.0580\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0536 - val_loss: 0.0531\n",
            "Winner: \n",
            "[[0.8551712339238297, 'linear'], [0.2179077616581372, 'softmax'], [0.2809106066057785, 'tanh'], ['linear'], ['linear'], ['adam']]\n",
            "Loser: \n",
            "[[0.21841876341515865, 'tanh'], [0.3898067501984548, 'sigmoid'], [0.813980083770169, 'sigmoid'], ['relu'], ['tanh'], ['sgd']]\n",
            "Child: \n",
            "[[0.21202710134011493, 'softmax'], [0.8185900303686223, 'linear'], [0.7441541282608646, 'sigmoid'], ['tanh'], ['sigmoid'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.2076 - val_loss: 0.1906\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1754 - val_loss: 0.1616\n",
            "__________________\n",
            "Generation: 74\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 7ms/step - loss: 0.0987 - val_loss: 0.1008\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0949 - val_loss: 0.0971\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0973 - val_loss: 0.1013\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0972 - val_loss: 0.1013\n",
            "Winner: \n",
            "[[0.8198100220193013, 'softmax'], [0.9205483448654188, 'sigmoid'], [0.8986108223070849, 'softmax'], ['relu'], ['softmax'], ['adam']]\n",
            "Loser: \n",
            "[[0.2733408000448573, 'linear'], [0.7801165277667977, 'tanh'], [0.5294921871642879, 'softmax'], ['sigmoid'], ['tanh'], ['sgd']]\n",
            "Child: \n",
            "[[0.6093382437057657, 'sigmoid'], [0.2676899457670978, 'linear'], [0.3572476898514032, 'sigmoid'], ['sigmoid'], ['relu'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0945 - val_loss: 0.0934\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0875 - val_loss: 0.0884\n",
            "__________________\n",
            "Generation: 75\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0658 - val_loss: 0.0580\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0532 - val_loss: 0.0520\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0507 - val_loss: 0.0408\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0376 - val_loss: 0.0374\n",
            "Winner: \n",
            "[[0.6198159910348582, 'linear'], [0.5590531582864904, 'sigmoid'], [0.5232156490604428, 'linear'], ['linear'], ['linear'], ['adam']]\n",
            "Loser: \n",
            "[[0.8551712339238297, 'linear'], [0.2179077616581372, 'softmax'], [0.2809106066057785, 'tanh'], ['linear'], ['linear'], ['adam']]\n",
            "Child: \n",
            "[[0.41133434352556664, 'relu'], [0.14169154461329436, 'softmax'], [0.8978324771688065, 'tanh'], ['relu'], ['sigmoid'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.2192 - val_loss: 0.2191\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2187 - val_loss: 0.2186\n",
            "__________________\n",
            "Generation: 76\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0477 - val_loss: 0.0396\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0372 - val_loss: 0.0365\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0428 - val_loss: 0.0406\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0388 - val_loss: 0.0394\n",
            "Winner: \n",
            "[[0.5380622704214664, 'sigmoid'], [0.6612472241653883, 'linear'], [0.7303843984040891, 'linear'], ['linear'], ['linear'], ['adam']]\n",
            "Loser: \n",
            "[[0.6198159910348582, 'linear'], [0.5590531582864904, 'sigmoid'], [0.5232156490604428, 'linear'], ['linear'], ['linear'], ['adam']]\n",
            "Child: \n",
            "[[0.23355117777065582, 'linear'], [0.5510108758172501, 'relu'], [0.5200321649185903, 'linear'], ['sigmoid'], ['linear'], ['adam']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0406 - val_loss: 0.0340\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0312 - val_loss: 0.0315\n",
            "__________________\n",
            "Generation: 77\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0431 - val_loss: 0.0383\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0345 - val_loss: 0.0347\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.2199 - val_loss: 0.2188\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.2176 - val_loss: 0.2165\n",
            "Winner: \n",
            "[[0.14734891885940837, 'linear'], [0.8668511904168803, 'relu'], [0.625084948095747, 'relu'], ['relu'], ['linear'], ['adam']]\n",
            "Loser: \n",
            "[[0.3867781271591094, 'tanh'], [0.39246395127774303, 'tanh'], [0.8567027532227195, 'linear'], ['relu'], ['sigmoid'], ['sgd']]\n",
            "Child: \n",
            "[[0.9337796549009854, 'relu'], [0.3239425131581505, 'softmax'], [0.7474430348183042, 'linear'], ['softmax'], ['relu'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0991 - val_loss: 0.1026\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0978 - val_loss: 0.1013\n",
            "__________________\n",
            "Generation: 78\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0993 - val_loss: 0.1024\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0972 - val_loss: 0.1002\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 4s 10ms/step - loss: 0.0650 - val_loss: 0.0546\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0509 - val_loss: 0.0513\n",
            "Winner: \n",
            "[[0.06670400127567278, 'tanh'], [0.9248402075573866, 'softmax'], [0.863528102337226, 'relu'], ['tanh'], ['tanh'], ['adam']]\n",
            "Loser: \n",
            "[[0.8633232522497706, 'sigmoid'], [0.08632177387565998, 'softmax'], [0.5324302641552852, 'tanh'], ['sigmoid'], ['linear'], ['sgd']]\n",
            "Child: \n",
            "[[0.32149427807586806, 'tanh'], [0.23989412212058403, 'sigmoid'], [0.0010012688234840583, 'linear'], ['sigmoid'], ['sigmoid'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2178 - val_loss: 0.2138\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2098 - val_loss: 0.2061\n",
            "__________________\n",
            "Generation: 79\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0657 - val_loss: 0.0575\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.0522 - val_loss: 0.0524\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0993 - val_loss: 0.1030\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0982 - val_loss: 0.1019\n",
            "Winner: \n",
            "[[0.06670400127567278, 'tanh'], [0.9248402075573866, 'softmax'], [0.863528102337226, 'relu'], ['tanh'], ['tanh'], ['adam']]\n",
            "Loser: \n",
            "[[0.4426912826157504, 'tanh'], [0.3377186292104849, 'softmax'], [0.37991486178823497, 'sigmoid'], ['sigmoid'], ['relu'], ['sgd']]\n",
            "Child: \n",
            "[[0.8659001581354294, 'softmax'], [0.13564394266866164, 'tanh'], [0.29749697439664957, 'linear'], ['sigmoid'], ['tanh'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.1050 - val_loss: 0.1056\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0993 - val_loss: 0.1011\n",
            "__________________\n",
            "Generation: 80\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0992 - val_loss: 0.1027\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0980 - val_loss: 0.1016\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 7ms/step - loss: 0.0968 - val_loss: 0.1000\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0955 - val_loss: 0.0995\n",
            "Winner: \n",
            "[[0.07239259482539318, 'relu'], [0.7062745973971906, 'tanh'], [0.8917064014342403, 'relu'], ['tanh'], ['softmax'], ['adam']]\n",
            "Loser: \n",
            "[[0.9337796549009854, 'relu'], [0.3239425131581505, 'softmax'], [0.7474430348183042, 'linear'], ['softmax'], ['relu'], ['sgd']]\n",
            "Child: \n",
            "[[0.25980274921392665, 'tanh'], [0.9542223700404167, 'linear'], [0.027180161931802282, 'sigmoid'], ['linear'], ['tanh'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1045 - val_loss: 0.1014\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0923 - val_loss: 0.0912\n",
            "__________________\n",
            "Generation: 81\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0968 - val_loss: 0.0998\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0954 - val_loss: 0.0995\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0455 - val_loss: 0.0406\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0394 - val_loss: 0.0401\n",
            "Winner: \n",
            "[[0.9699998233795569, 'softmax'], [0.4421759037095453, 'tanh'], [0.1943194616753452, 'tanh'], ['relu'], ['tanh'], ['adam']]\n",
            "Loser: \n",
            "[[0.07239259482539318, 'relu'], [0.7062745973971906, 'tanh'], [0.8917064014342403, 'relu'], ['tanh'], ['softmax'], ['adam']]\n",
            "Child: \n",
            "[[0.2202223759554388, 'softmax'], [0.958866449472049, 'tanh'], [0.9640602803318199, 'tanh'], ['relu'], ['relu'], ['adam']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 5s 14ms/step - loss: 0.0426 - val_loss: 0.0395\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0377 - val_loss: 0.0380\n",
            "__________________\n",
            "Generation: 82\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 4s 9ms/step - loss: 0.0973 - val_loss: 0.1013\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0972 - val_loss: 0.1013\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.1051 - val_loss: 0.1060\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0997 - val_loss: 0.1020\n",
            "Winner: \n",
            "[[0.8198100220193013, 'softmax'], [0.9205483448654188, 'sigmoid'], [0.8986108223070849, 'softmax'], ['relu'], ['softmax'], ['adam']]\n",
            "Loser: \n",
            "[[0.8659001581354294, 'softmax'], [0.13564394266866164, 'tanh'], [0.29749697439664957, 'linear'], ['sigmoid'], ['tanh'], ['sgd']]\n",
            "Child: \n",
            "[[0.08617669076192802, 'softmax'], [0.27900405389107186, 'tanh'], [0.26905103728044666, 'linear'], ['softmax'], ['linear'], ['adam']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0457 - val_loss: 0.0399\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0387 - val_loss: 0.0394\n",
            "__________________\n",
            "Generation: 83\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0668 - val_loss: 0.0610\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0534 - val_loss: 0.0530\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 4s 10ms/step - loss: 0.0428 - val_loss: 0.0397\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0376 - val_loss: 0.0379\n",
            "Winner: \n",
            "[[0.2202223759554388, 'softmax'], [0.958866449472049, 'tanh'], [0.9640602803318199, 'tanh'], ['relu'], ['relu'], ['adam']]\n",
            "Loser: \n",
            "[[0.6071943542230277, 'softmax'], [0.8349384059065131, 'linear'], [0.5075192135708624, 'sigmoid'], ['linear'], ['relu'], ['adam']]\n",
            "Child: \n",
            "[[0.34887941422078816, 'relu'], [0.03895079187786743, 'tanh'], [0.3382375631112071, 'relu'], ['softmax'], ['sigmoid'], ['adam']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0990 - val_loss: 0.0629\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0588 - val_loss: 0.0594\n",
            "__________________\n",
            "Generation: 84\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 4s 9ms/step - loss: 0.0973 - val_loss: 0.1013\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0972 - val_loss: 0.1013\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 4s 10ms/step - loss: 0.1636 - val_loss: 0.1228\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1027 - val_loss: 0.0899\n",
            "Winner: \n",
            "[[0.8198100220193013, 'softmax'], [0.9205483448654188, 'sigmoid'], [0.8986108223070849, 'softmax'], ['relu'], ['softmax'], ['adam']]\n",
            "Loser: \n",
            "[[0.652066626556296, 'softmax'], [0.8277469204055975, 'softmax'], [0.9584768163936012, 'tanh'], ['sigmoid'], ['sigmoid'], ['adam']]\n",
            "Child: \n",
            "[[0.4495345799275643, 'sigmoid'], [0.4214958813449954, 'softmax'], [0.3314223269952846, 'softmax'], ['softmax'], ['sigmoid'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.2194 - val_loss: 0.2193\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.2189 - val_loss: 0.2188\n",
            "__________________\n",
            "Generation: 85\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0452 - val_loss: 0.0411\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0396 - val_loss: 0.0402\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0939 - val_loss: 0.0894\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0822 - val_loss: 0.0821\n",
            "Winner: \n",
            "[[0.9699998233795569, 'softmax'], [0.4421759037095453, 'tanh'], [0.1943194616753452, 'tanh'], ['relu'], ['tanh'], ['adam']]\n",
            "Loser: \n",
            "[[0.6093382437057657, 'sigmoid'], [0.2676899457670978, 'linear'], [0.3572476898514032, 'sigmoid'], ['sigmoid'], ['relu'], ['sgd']]\n",
            "Child: \n",
            "[[0.8631068786026868, 'tanh'], [0.0481748211842532, 'relu'], [0.11441950268777512, 'linear'], ['relu'], ['tanh'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.1007 - val_loss: 0.1036\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0981 - val_loss: 0.1011\n",
            "__________________\n",
            "Generation: 86\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0398 - val_loss: 0.0340\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0312 - val_loss: 0.0313\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0408 - val_loss: 0.0332\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0309 - val_loss: 0.0310\n",
            "Winner: \n",
            "[[0.14648538118669685, 'softmax'], [0.6489160368156419, 'relu'], [0.43646250883541826, 'linear'], ['softmax'], ['tanh'], ['adam']]\n",
            "Loser: \n",
            "[[0.23355117777065582, 'linear'], [0.5510108758172501, 'relu'], [0.5200321649185903, 'linear'], ['sigmoid'], ['linear'], ['adam']]\n",
            "Child: \n",
            "[[0.7424340120657617, 'softmax'], [0.7604478715164593, 'linear'], [0.0740858387440646, 'softmax'], ['tanh'], ['relu'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0961 - val_loss: 0.0986\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.0931 - val_loss: 0.0956\n",
            "__________________\n",
            "Generation: 87\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0997 - val_loss: 0.1013\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0952 - val_loss: 0.0970\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0990 - val_loss: 0.0627\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0587 - val_loss: 0.0593\n",
            "Winner: \n",
            "[[0.34887941422078816, 'relu'], [0.03895079187786743, 'tanh'], [0.3382375631112071, 'relu'], ['softmax'], ['sigmoid'], ['adam']]\n",
            "Loser: \n",
            "[[0.7972524082377281, 'linear'], [0.6151658684152892, 'tanh'], [0.03943394329032357, 'tanh'], ['sigmoid'], ['linear'], ['sgd']]\n",
            "Child: \n",
            "[[0.6834753966892522, 'linear'], [0.5741697922682576, 'sigmoid'], [0.8488282628564952, 'tanh'], ['tanh'], ['softmax'], ['adam']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 7ms/step - loss: 0.0974 - val_loss: 0.1013\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0971 - val_loss: 0.1013\n",
            "__________________\n",
            "Generation: 88\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0973 - val_loss: 0.0630\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0589 - val_loss: 0.0594\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1063 - val_loss: 0.1016\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0915 - val_loss: 0.0896\n",
            "Winner: \n",
            "[[0.34887941422078816, 'relu'], [0.03895079187786743, 'tanh'], [0.3382375631112071, 'relu'], ['softmax'], ['sigmoid'], ['adam']]\n",
            "Loser: \n",
            "[[0.25980274921392665, 'tanh'], [0.9542223700404167, 'linear'], [0.027180161931802282, 'sigmoid'], ['linear'], ['tanh'], ['sgd']]\n",
            "Child: \n",
            "[[0.42398913266697325, 'softmax'], [0.4142905077319913, 'linear'], [0.15491462486764163, 'linear'], ['relu'], ['softmax'], ['adam']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0961 - val_loss: 0.0995\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0952 - val_loss: 0.0994\n",
            "__________________\n",
            "Generation: 89\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0963 - val_loss: 0.0997\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.0954 - val_loss: 0.0994\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0460 - val_loss: 0.0407\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0392 - val_loss: 0.0399\n",
            "Winner: \n",
            "[[0.9699998233795569, 'softmax'], [0.4421759037095453, 'tanh'], [0.1943194616753452, 'tanh'], ['relu'], ['tanh'], ['adam']]\n",
            "Loser: \n",
            "[[0.42398913266697325, 'softmax'], [0.4142905077319913, 'linear'], [0.15491462486764163, 'linear'], ['relu'], ['softmax'], ['adam']]\n",
            "Child: \n",
            "[[0.23323472581563276, 'tanh'], [0.08843898340673051, 'linear'], [0.7887908046949648, 'linear'], ['sigmoid'], ['relu'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0948 - val_loss: 0.0976\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0930 - val_loss: 0.0955\n",
            "__________________\n",
            "Generation: 90\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1040 - val_loss: 0.1050\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0990 - val_loss: 0.1017\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 4s 10ms/step - loss: 0.0655 - val_loss: 0.0557\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0513 - val_loss: 0.0519\n",
            "Winner: \n",
            "[[0.06670400127567278, 'tanh'], [0.9248402075573866, 'softmax'], [0.863528102337226, 'relu'], ['tanh'], ['tanh'], ['adam']]\n",
            "Loser: \n",
            "[[0.8631068786026868, 'tanh'], [0.0481748211842532, 'relu'], [0.11441950268777512, 'linear'], ['relu'], ['tanh'], ['sgd']]\n",
            "Child: \n",
            "[[0.48395162159716787, 'relu'], [0.7421009744157522, 'linear'], [0.84693384466854, 'relu'], ['relu'], ['softmax'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "__________________\n",
            "Generation: 91\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.2191 - val_loss: 0.2153\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.2115 - val_loss: 0.2080\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Winner: \n",
            "[[0.48395162159716787, 'relu'], [0.7421009744157522, 'linear'], [0.84693384466854, 'relu'], ['relu'], ['softmax'], ['sgd']]\n",
            "Loser: \n",
            "[[0.32149427807586806, 'tanh'], [0.23989412212058403, 'sigmoid'], [0.0010012688234840583, 'linear'], ['sigmoid'], ['sigmoid'], ['sgd']]\n",
            "Child: \n",
            "[[0.9476448826366644, 'sigmoid'], [0.9077809725685024, 'linear'], [0.6220220502940603, 'sigmoid'], ['tanh'], ['relu'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 7ms/step - loss: 0.0985 - val_loss: 0.0862\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0813 - val_loss: 0.0838\n",
            "__________________\n",
            "Generation: 92\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0403 - val_loss: 0.0337\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0312 - val_loss: 0.0316\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 7ms/step - loss: 0.0423 - val_loss: 0.0400\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0387 - val_loss: 0.0395\n",
            "Winner: \n",
            "[[0.14648538118669685, 'softmax'], [0.6489160368156419, 'relu'], [0.43646250883541826, 'linear'], ['softmax'], ['tanh'], ['adam']]\n",
            "Loser: \n",
            "[[0.5380622704214664, 'sigmoid'], [0.6612472241653883, 'linear'], [0.7303843984040891, 'linear'], ['linear'], ['linear'], ['adam']]\n",
            "Child: \n",
            "[[0.012869780779711681, 'relu'], [0.18089132336907965, 'sigmoid'], [0.3206919382301592, 'linear'], ['linear'], ['linear'], ['adam']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0554 - val_loss: 0.0462\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0407 - val_loss: 0.0399\n",
            "__________________\n",
            "Generation: 93\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0989 - val_loss: 0.1019\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0965 - val_loss: 0.0995\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0451 - val_loss: 0.0405\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0393 - val_loss: 0.0399\n",
            "Winner: \n",
            "[[0.9699998233795569, 'softmax'], [0.4421759037095453, 'tanh'], [0.1943194616753452, 'tanh'], ['relu'], ['tanh'], ['adam']]\n",
            "Loser: \n",
            "[[0.9501626872306544, 'softmax'], [0.03782411737233382, 'tanh'], [0.6989668363081517, 'softmax'], ['linear'], ['linear'], ['sgd']]\n",
            "Child: \n",
            "[[0.04054294863332908, 'tanh'], [0.700493445438518, 'softmax'], [0.5920613919355334, 'tanh'], ['tanh'], ['tanh'], ['adam']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 7ms/step - loss: 0.0651 - val_loss: 0.0581\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0561 - val_loss: 0.0580\n",
            "__________________\n",
            "Generation: 94\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0934 - val_loss: 0.0956\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0902 - val_loss: 0.0921\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0423 - val_loss: 0.0392\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0377 - val_loss: 0.0383\n",
            "Winner: \n",
            "[[0.2202223759554388, 'softmax'], [0.958866449472049, 'tanh'], [0.9640602803318199, 'tanh'], ['relu'], ['relu'], ['adam']]\n",
            "Loser: \n",
            "[[0.23323472581563276, 'tanh'], [0.08843898340673051, 'linear'], [0.7887908046949648, 'linear'], ['sigmoid'], ['relu'], ['sgd']]\n",
            "Child: \n",
            "[[0.645061469501986, 'tanh'], [0.04166642091085582, 'sigmoid'], [0.8554202274672411, 'relu'], ['sigmoid'], ['linear'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.1199 - val_loss: 0.1180\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1086 - val_loss: 0.1078\n",
            "__________________\n",
            "Generation: 95\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 7ms/step - loss: 0.0973 - val_loss: 0.1013\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0971 - val_loss: 0.1007\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0464 - val_loss: 0.0395\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0363 - val_loss: 0.0359\n",
            "Winner: \n",
            "[[0.14734891885940837, 'linear'], [0.8668511904168803, 'relu'], [0.625084948095747, 'relu'], ['relu'], ['linear'], ['adam']]\n",
            "Loser: \n",
            "[[0.6834753966892522, 'linear'], [0.5741697922682576, 'sigmoid'], [0.8488282628564952, 'tanh'], ['tanh'], ['softmax'], ['adam']]\n",
            "Child: \n",
            "[[0.7206711154224192, 'relu'], [0.9676265274075875, 'relu'], [0.6391125634741789, 'tanh'], ['sigmoid'], ['softmax'], ['adam']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 4s 10ms/step - loss: 0.0974 - val_loss: 0.1013\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0972 - val_loss: 0.1013\n",
            "__________________\n",
            "Generation: 96\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0396 - val_loss: 0.0328\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0307 - val_loss: 0.0307\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0451 - val_loss: 0.0397\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0384 - val_loss: 0.0386\n",
            "Winner: \n",
            "[[0.14648538118669685, 'softmax'], [0.6489160368156419, 'relu'], [0.43646250883541826, 'linear'], ['softmax'], ['tanh'], ['adam']]\n",
            "Loser: \n",
            "[[0.08617669076192802, 'softmax'], [0.27900405389107186, 'tanh'], [0.26905103728044666, 'linear'], ['softmax'], ['linear'], ['adam']]\n",
            "Child: \n",
            "[[0.4754590127899453, 'linear'], [0.9391354155629232, 'relu'], [0.5712735398570843, 'tanh'], ['sigmoid'], ['relu'], ['adam']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0464 - val_loss: 0.0382\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0336 - val_loss: 0.0331\n",
            "__________________\n",
            "Generation: 97\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 7ms/step - loss: 0.0439 - val_loss: 0.0401\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0389 - val_loss: 0.0395\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0494 - val_loss: 0.0416\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0375 - val_loss: 0.0352\n",
            "Winner: \n",
            "[[0.569814623064877, 'tanh'], [0.8448147666569815, 'tanh'], [0.09883656670056751, 'tanh'], ['linear'], ['linear'], ['adam']]\n",
            "Loser: \n",
            "[[0.14734891885940837, 'linear'], [0.8668511904168803, 'relu'], [0.625084948095747, 'relu'], ['relu'], ['linear'], ['adam']]\n",
            "Child: \n",
            "[[0.5746710047761823, 'softmax'], [0.3112118877708655, 'linear'], [0.23639562868631436, 'tanh'], ['linear'], ['softmax'], ['adam']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0975 - val_loss: 0.1013\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0964 - val_loss: 0.1000\n",
            "__________________\n",
            "Generation: 98\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1193 - val_loss: 0.1175\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1083 - val_loss: 0.1074\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 7ms/step - loss: 0.0930 - val_loss: 0.0842\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0798 - val_loss: 0.0821\n",
            "Winner: \n",
            "[[0.9476448826366644, 'sigmoid'], [0.9077809725685024, 'linear'], [0.6220220502940603, 'sigmoid'], ['tanh'], ['relu'], ['sgd']]\n",
            "Loser: \n",
            "[[0.645061469501986, 'tanh'], [0.04166642091085582, 'sigmoid'], [0.8554202274672411, 'relu'], ['sigmoid'], ['linear'], ['sgd']]\n",
            "Child: \n",
            "[[0.4034319780434201, 'relu'], [0.8010322339764634, 'tanh'], [0.8527632355507634, 'tanh'], ['linear'], ['relu'], ['adam']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0440 - val_loss: 0.0393\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0378 - val_loss: 0.0386\n",
            "__________________\n",
            "Generation: 99\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0967 - val_loss: 0.0999\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.0956 - val_loss: 0.0997\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0968 - val_loss: 0.0639\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0594 - val_loss: 0.0597\n",
            "Winner: \n",
            "[[0.5746710047761823, 'softmax'], [0.3112118877708655, 'linear'], [0.23639562868631436, 'tanh'], ['linear'], ['softmax'], ['adam']]\n",
            "Loser: \n",
            "[[0.34887941422078816, 'relu'], [0.03895079187786743, 'tanh'], [0.3382375631112071, 'relu'], ['softmax'], ['sigmoid'], ['adam']]\n",
            "Child: \n",
            "[[0.9599119997380642, 'tanh'], [0.8526009129130931, 'linear'], [0.15669536004844975, 'relu'], ['softmax'], ['softmax'], ['sgd']]\n",
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0997 - val_loss: 0.1039\n",
            "__________________\n"
          ]
        }
      ],
      "source": [
        "result,best_architecture = GA(population,n_generations=100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "This code creates a final best autoencoder model using the last best architecture found from the GA function. It uses the create_model() function to create the model and passed in the best architecture and code size. Then it compiles the model with the optimizer and loss function (mean squared error) found in the best architecture. This final model can be trained and used for the specific task.\n",
        "'''\n",
        "best_model = create_model(best_architecture[-1],4)\n",
        "best_model.compile(optimizer=best_architecture[-1][-1].optimizer, loss=\"mse\")"
      ],
      "metadata": {
        "id": "WkR9v1RTvqDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(best_model,2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXcHDC9CwVCD",
        "outputId": "2b3e4519-5b6c-4739-8d91-85d65f483014"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0410 - val_loss: 0.0340\n",
            "Epoch 2/2\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0314 - val_loss: 0.0315\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff856de3100>"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_imgs = best_model.encoder(X_test).numpy()\n",
        "decoded_imgs = best_model.decoder(encoded_imgs).numpy()"
      ],
      "metadata": {
        "id": "dDQbvS9vvwH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This code is used to display the original and decoded images side by side.\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "  # display original\n",
        "  ax = plt.subplot(2, n, i + 1)\n",
        "  plt.imshow(X_test[i])\n",
        "  plt.title(\"original\")\n",
        "  plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "\n",
        "  # display reconstruction\n",
        "  ax = plt.subplot(2, n, i + 1 + n)\n",
        "  plt.imshow(decoded_imgs[i])\n",
        "  plt.title(\"reconstructed\")\n",
        "  plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "i4M3kJF4v547",
        "outputId": "8f739c9f-628c-41c7-a6bb-d0fddecad4b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x288 with 20 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_architecture_with_real_values(best_architecture[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5NoW4eeNE3Q",
        "outputId": "ad5485b1-6581-4633-e642-aac23b251a63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[38, 'softmax'], [25, 'relu'], [11, 'linear'], ['softmax'], ['tanh'], ['adam']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_architecture(best_architecture[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btj4pDN-qLKA",
        "outputId": "b5c2a52b-2712-4de4-ef68-70dbb4818da5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.14648538118669685, 'softmax'], [0.6489160368156419, 'relu'], [0.43646250883541826, 'linear'], ['softmax'], ['tanh'], ['adam']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-jmExOzindW"
      },
      "outputs": [],
      "source": [
        "#This function is used to plot the fitness of the best offspring over the generations of the GA algorithm. \n",
        "from matplotlib import pyplot as plt\n",
        "def plot(offspring_fitness_over_time):\n",
        "  plt.figure(figsize=(8, 6), dpi=80)\n",
        "  plt.plot(result)\n",
        "  plt.xlabel(\"Generations\")\n",
        "  plt.ylabel(\"Fitness\")\n",
        "  plt.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "4T-yEqn0irHz",
        "outputId": "07a6aaa6-e77f-42a1-9630-35c3e80aaa2c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot(result)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
